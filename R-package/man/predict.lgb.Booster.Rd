% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lgb.Booster.R
\name{predict.lgb.Booster}
\alias{predict.lgb.Booster}
\title{Predict method for LightGBM model}
\usage{
\method{predict}{lgb.Booster}(
  object,
  newdata,
  type = "link",
  start_iteration = NULL,
  num_iteration = NULL,
  header = FALSE,
  params = list(),
  ...
)
}
\arguments{
\item{object}{Object of class \code{lgb.Booster}}

\item{newdata}{a \code{matrix} object, a \code{dgCMatrix} object or
a character representing a path to a text file (CSV, TSV, or LibSVM)}

\item{type}{Type of prediction to output. Allowed types are:\itemize{
            \item \code{"link"}: will output the predicted score according to the objective function being
                  optimized (depending on the link function that the objective uses), after applying any necessary
                  transformations - for example, for \code{objective="binary"}, it will output class probabilities.
            \item \code{"response"}: for classification objectives, will output the class with the highest predicted
                  probability. For other objectives, will output the same as "link".
            \item \code{"raw"}: will output the non-transformed numbers (sum of predictions from boosting iterations'
                  results) from which the "link" number is produced for a given objective function - for example, for
                  \code{objective="binary"}, this corresponds to log-odds. For many objectives such as "regression",
                  since no transformation is applied, the output will be the same as for "link".
            \item \code{"leaf"}: will output the index of the terminal node / leaf at which each observations falls
                  in each tree in the model, outputted as integers, with one column per tree.
            \item \code{"contrib"}: will return the per-feature contributions for each prediction, including an
                  intercept (each feature will produce one column). If there are multiple classes, each class will
                  have separate feature contributions (thus the number of columns is feaures+1 multiplied by the
                  number of classes).
            }

            Note that, if using custom objectives, types "link" and "response" will not be available and will
            default towards using "raw" instead.}

\item{start_iteration}{int or None, optional (default=None)
Start index of the iteration to predict.
If None or <= 0, starts from the first iteration.}

\item{num_iteration}{int or None, optional (default=None)
Limit number of iterations in the prediction.
If None, if the best iteration exists and start_iteration is None or <= 0, the
best iteration is used; otherwise, all iterations from start_iteration are used.
If <= 0, all iterations from start_iteration are used (no limits).}

\item{header}{only used for prediction for text file. True if text file has header}

\item{params}{a list of additional named parameters. See
\href{https://lightgbm.readthedocs.io/en/latest/Parameters.html#predict-parameters}{
the "Predict Parameters" section of the documentation} for a list of parameters and
valid values.}

\item{...}{ignored}
}
\value{
For prediction types that are meant to always return one output per observation (e.g. when predicting
        \code{type="link"} on a binary classification or regression objective), will return a vector with one
        row per observation in \code{newdata}.

        For prediction types that are meant to return more than one output per observation (e.g. when predicting
        \code{type="link"} on a multi-class objective, or when predicting \code{type="leaf"}, regardless of
        objective), will return a matrix with one row per observation in \code{newdata} and one column per output.
}
\description{
Predicted values based on class \code{lgb.Booster}
}
\examples{
\donttest{
data(agaricus.train, package = "lightgbm")
train <- agaricus.train
dtrain <- lgb.Dataset(train$data, label = train$label)
data(agaricus.test, package = "lightgbm")
test <- agaricus.test
dtest <- lgb.Dataset.create.valid(dtrain, test$data, label = test$label)
params <- list(
  objective = "regression"
  , metric = "l2"
  , min_data = 1L
  , learning_rate = 1.0
)
valids <- list(test = dtest)
model <- lgb.train(
  params = params
  , data = dtrain
  , nrounds = 5L
  , valids = valids
)
preds <- predict(model, test$data)

# pass other prediction parameters
preds <- predict(
    model,
    test$data,
    params = list(
        predict_disable_shape_check = TRUE
   )
)
}
}
