trigger:
  branches:
    include:
      - master
pr:
  - master
variables:
  CMAKE_BUILD_PARALLEL_LEVEL: 4
  PYTHON_VERSION: '3.13'
  runCodesignValidationInjection: false
  skipComponentGovernanceDetection: true
  Codeql.Enabled: false
  Codeql.SkipTaskAutoInjection: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  SKBUILD_STRICT_CONFIG: true
resources:
  # The __work/ directory, where Azure DevOps writes the source files, needs to be read-write because
  # LightGBM's CI jobs write files in the source directory.
  #
  # For all the containers included here, all other directories that Azure mounts in are mounted as read-only
  # to minimize the risk of side effects from one run affecting future runs.
  # ref: https://learn.microsoft.com/en-us/azure/devops/pipelines/yaml-schema/resources-containers-container
  containers:
    - container: linux-artifact-builder
      image: lightgbm.azurecr.io/vsts-agent:manylinux_2_28_x86_64
      mountReadOnly:
        work: false
        externals: true
        tools: true
        tasks: true
    - container: ubuntu-latest
      image: mcr.microsoft.com/mirror/docker/library/ubuntu:22.04
      options: "--name ci-container -v /usr/bin/docker:/tmp/docker:ro"
      mountReadOnly:
        work: false
        externals: true
        tools: true
        tasks: true
jobs:
  ###############
  # Maintenance #
  ###############
  - job: Maintenance
    pool: lightgbm_agent_pool_ado
    container: ubuntu-latest
    # routine maintenance (like periodically deleting old files),
    # to be run on 1 random CI runner in the self-hosted pool each runner
    steps:
      - script: |
          print-diagnostics(){
            echo "---- df -h -m ----"
            df -h -m
            echo "---- docker system df ----"
            /tmp/docker system df
            echo "---- docker images ----"
            /tmp/docker images
          }
          # check disk usage
          print-diagnostics
          # remove old containers, container images, volumes
          # ref: https://stackoverflow.com/a/32723127/3986677
          # ref: https://depot.dev/blog/docker-clear-cache#removing-everything-with-docker-system-prune
          echo "---- running 'docker system prune' ----"
          /tmp/docker system prune \
            --all \
            --force \
            --volumes \
            --filter until=720h
          # check disk usage again
          print-diagnostics
        displayName: Clean
  #########
  # Linux #
  #########
  - job: Linux
    variables:
      COMPILER: gcc
      SETUP_CONDA: 'false'
      OS_NAME: 'linux'
      PRODUCES_ARTIFACTS: 'false'
    pool: lightgbm_agent_pool_ado
    container: linux-artifact-builder
    strategy:
      matrix:
        gpu_source:
          TASK: gpu
          METHOD: source
    steps:
      - script: |
          echo "##vso[task.setvariable variable=BUILD_DIRECTORY]$BUILD_SOURCESDIRECTORY"
          echo "##vso[task.prependpath]$CONDA/bin"
        displayName: 'Set variables'
      - script: |
          git clean -d -f -x
        displayName: 'Clean source directory'
      - script: |
          echo '$(Build.SourceVersion)' > '$(Build.ArtifactStagingDirectory)/commit.txt'
        displayName: 'Add commit hash to artifacts archive'
      - task: Bash@3
        displayName: Setup
        inputs:
          filePath: $(Build.SourcesDirectory)/.ci/setup.sh
          targetType: filePath
      - task: Bash@3
        displayName: Test
        inputs:
          filePath: $(Build.SourcesDirectory)/.ci/test.sh
          targetType: filePath
  ################
  # Linux_latest #
  ################
  - job: Linux_latest
    variables:
      COMPILER: clang-17
      DEBIAN_FRONTEND: 'noninteractive'
      IN_UBUNTU_BASE_CONTAINER: 'true'
      OS_NAME: 'linux'
      SETUP_CONDA: 'true'
    pool: lightgbm_agent_pool_ado
    container: ubuntu-latest
    strategy:
      matrix:
        gpu_source:
          TASK: gpu
          METHOD: source
          PYTHON_VERSION: '3.12'
        gpu_pip:
          TASK: gpu
          METHOD: pip
          PYTHON_VERSION: '3.11'
        gpu_wheel:
          TASK: gpu
          METHOD: wheel
          PYTHON_VERSION: '3.10'
    steps:
      - script: |
          echo "##vso[task.setvariable variable=BUILD_DIRECTORY]$BUILD_SOURCESDIRECTORY"
          CONDA=$HOME/miniforge
          echo "##vso[task.setvariable variable=CONDA]$CONDA"
          echo "##vso[task.prependpath]$CONDA/bin"
        displayName: 'Set variables'
      # https://github.com/microsoft/azure-pipelines-agent/issues/2043#issuecomment-687983301
      - script: |
          /tmp/docker exec -t -u 0 ci-container \
          sh -c "apt-get update && apt-get -o Dpkg::Options::="--force-confold" -y install sudo"
        displayName: 'Install sudo'
      - script: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends git
          git clean -d -f -x
        displayName: 'Clean source directory'
      - task: Bash@3
        displayName: Setup
        inputs:
          filePath: $(Build.SourcesDirectory)/.ci/setup.sh
          targetType: 'filePath'
      - task: Bash@3
        displayName: Test
        inputs:
          filePath: $(Build.SourcesDirectory)/.ci/test.sh
          targetType: 'filePath'

  ###########
  # Package #
  ###########
  - job: Package
    dependsOn:
      - Linux
      - Linux_latest
    condition: and(succeeded(), not(startsWith(variables['Build.SourceBranch'], 'refs/pull/')))
    pool:
      vmImage: 'ubuntu-22.04'
    steps:
      # Create archives with complete source code included (with git submodules)
      - task: ArchiveFiles@2
        displayName: Create tar.gz archive
        condition: and(succeeded(), startsWith(variables['Build.SourceBranch'], 'refs/tags/v'))
        inputs:
          rootFolderOrFile: $(Build.SourcesDirectory)
          includeRootFolder: false
          archiveType: tar
          tarCompression: gz
          archiveFile: '$(Build.ArtifactStagingDirectory)/archives/LightGBM-complete_source_code_tar_gz.tar.gz'
          replaceExistingArchive: true
      # Download all agent packages from all previous phases
      - task: DownloadBuildArtifacts@0
        displayName: Download package assets
        inputs:
          artifactName: PackageAssets
          downloadPath: $(Build.SourcesDirectory)/binaries
      - script: |
          python "$(Build.SourcesDirectory)/.ci/create-nuget.py" "$(Build.SourcesDirectory)/binaries/PackageAssets"
        displayName: 'Create NuGet configuration files'
      - task: NuGetCommand@2
        inputs:
          command: pack
          packagesToPack: '$(Build.SourcesDirectory)/.ci/nuget/*.nuspec'
          packDestination: '$(Build.ArtifactStagingDirectory)/nuget'
      - task: PublishBuildArtifacts@1
        inputs:
          pathtoPublish: '$(Build.ArtifactStagingDirectory)/nuget'
          artifactName: NuGet
          artifactType: container
