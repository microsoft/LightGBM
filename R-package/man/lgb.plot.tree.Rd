% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lgb.plot.tree.R
\name{lgb.plot.tree}
\alias{lgb.plot.tree}
\title{Plot LightGBM trees.}
\usage{
lgb.plot.tree(
  model = NULL,
  tree = NULL,
  rules = NULL,
  render = TRUE,
  plot_width = NULL,
  plot_height = NULL
)
}
\arguments{
\item{model}{a \code{lgb.Booster} object.}

\item{tree}{An integer vector of tree indices that should be visualized IMPORTANT:
the tree index in lightgbm is zero-based, i.e. use tree = 0 for the first tree in a model.}

\item{rules}{a list of rules to replace the split values with feature levels.}

\item{render}{a logical flag for whether the graph should be rendered (see Value).}

\item{plot_width}{the width of the diagram in pixels.}

\item{plot_height}{the height of the diagram in pixels.}
}
\value{
When \code{render = TRUE}:
returns a rendered graph object which is an \code{htmlwidget} of class \code{grViz}.
Similar to ggplot objects, it needs to be printed to see it when not running from command line.

When \code{render = FALSE}:
silently returns a graph object which is of DiagrammeR's class \code{dgr_graph}.
This could be useful if one wants to modify some of the graph attributes
before rendering the graph with \code{\link[DiagrammeR]{render_graph}}.
}
\description{
The \code{lgb.plot.tree} function creates a DiagrammeR plot of one or more LightGBM trees.
}
\details{
The \code{lgb.plot.tree} function creates a DiagrammeR plot of a single LightGBM tree.
The tree is extracted from the model and displayed as a directed graph.
The nodes are labelled with the feature, split value, gain, count and value.
The edges are labelled with the decision type and split value.
}
\examples{
\donttest{
\dontshow{setLGBMthreads(2L)}
\dontshow{data.table::setDTthreads(1L)}
# Example One
data(agaricus.train, package = "lightgbm")
train <- agaricus.train
dtrain <- lgb.Dataset(train$data, label = train$label)
params <- list(
  objective = "regression"
  , metric = "l2"
  , min_data = 1L
  , learning_rate = 0.3
  , num_leaves = 5L
)
model <- lgb.train(
  params = params
  , data = dtrain
  , nrounds = 5L
)

# Plot the first tree
lgb.plot.tree(model, 0L)

# Plot the first and fifth trees
lgb.plot.tree(model, c(0L,4L))

# Example Two - model uses categorical features
data(bank, package = "lightgbm")

# We are dividing the dataset into two: one train, one validation
bank_train <- bank[1L:4000L, ]
bank_test <- bank[4001L:4521L, ]

# We must now transform the data to fit in LightGBM
# For this task, we use lgb.convert_with_rules
# The function transforms the data into a fittable data
bank_rules <- lgb.convert_with_rules(data = bank_train)
bank_train <- bank_rules$data

# Remove 1 to label because it must be between 0 and 1
bank_train$y <- bank_train$y - 1L

# Data input to LightGBM must be a matrix, without the label
my_data_train <- as.matrix(bank_train[, 1L:16L, with = FALSE])

# Creating the LightGBM dataset with categorical features
# The categorical features can be passed to lgb.train to not copy and paste a lot
dtrain <- lgb.Dataset(
  data = my_data_train
  , label = bank_train$y
  , categorical_feature = c(2L, 3L, 4L, 5L, 7L, 8L, 9L, 11L, 16L)
)

# Train the model with 5 training rounds
params <- list(
  objective = "binary"
  , metric = "l2"
  , learning_rate = 0.1
  , num_leaves = 5L
)
model_bank <- lgb.train(
  params = params
  , data = dtrain
  , nrounds = 5L
)

# Plot the first two trees in the model without specifying "rules"
lgb.plot.tree(model_bank, tree = 0L:1L)

# Plot the first two trees in the model specifying "rules"
lgb.plot.tree(model_bank, rules = bank_rules$rules, tree = 0L:1L)

}
}
