{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use `lightgbm.dask` to train a LightGBM model on data stored as a [Dask DataFrame](https://docs.dask.org/en/latest/dataframe.html) or [Dask Array](https://docs.dask.org/en/latest/array.html).\n",
    "\n",
    "It uses `FargateCluster` from [`dask-cloudprovider`](https://github.com/dask/dask-cloudprovider) to create a distributed cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Set up a cluster on AWS Fargate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ecr-details.json\", \"r\") as f:\n",
    "    ecr_details = json.loads(f.read())\n",
    "\n",
    "CONTAINER_IMAGE = ecr_details[\"repository\"][\"repositoryUri\"] + \":1\"\n",
    "print(f\"scheduler and worker image: {CONTAINER_IMAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, set up your AWS credentials. If you're unsure how to do this, see [the AWS docs](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a cluster with 3 workers. See https://cloudprovider.dask.org/en/latest/aws.html#dask_cloudprovider.aws.FargateCluster for more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cloudprovider.aws import FargateCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "n_workers = 3\n",
    "cluster = FargateCluster(\n",
    "    image=CONTAINER_IMAGE,\n",
    "    worker_cpu=512,\n",
    "    worker_mem=4096,\n",
    "    n_workers=n_workers,\n",
    "    fargate_use_private_ip=False,\n",
    "    scheduler_timeout=\"40 minutes\",\n",
    "    find_address_timeout=60 * 10,\n",
    ")\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"View the dashboard: {cluster.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the link above to view a diagnostic dashboard while you run the training code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask.distributed import wait\n",
    "from lightgbm.dask import DaskLGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"attempt {i}\")\n",
    "    \n",
    "    client.restart()\n",
    "\n",
    "    num_rows = 1e6\n",
    "    num_features = 1e2\n",
    "    num_partitions = 10\n",
    "    rows_per_chunk = num_rows / num_partitions\n",
    "\n",
    "    data = da.random.random((num_rows, num_features), (rows_per_chunk, num_features))\n",
    "\n",
    "    labels = da.random.random((num_rows, 1), (rows_per_chunk, 1))\n",
    "\n",
    "    data = data.persist()\n",
    "    labels = labels.persist()\n",
    "    _ = wait(data)\n",
    "    _ = wait(labels)\n",
    "\n",
    "    dask_reg = DaskLGBMRegressor(\n",
    "        silent=False,\n",
    "        max_depth=5,\n",
    "        random_state=708,\n",
    "        objective=\"regression_l2\",\n",
    "        learning_rate=0.1,\n",
    "        tree_learner=\"data\",\n",
    "        n_estimators=10,\n",
    "        min_child_samples=1,\n",
    "        n_jobs=-1,\n",
    "        local_listen_port=12400,\n",
    "    )\n",
    "\n",
    "    dask_reg.fit(\n",
    "        client=client,\n",
    "        X=data,\n",
    "        y=labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model produced by this training run is an instance of `DaskLGBMRegressor`. To get a regular non-Dask model (which can be pickled and saved), run `.to_local()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = dask_reg.to_local()\n",
    "type(local_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize this model by looking at a data frame representation of it. You can also check that the model really used inputs from all workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_reg.booster_.trees_to_dataframe().iloc[0,][\"count\"] == 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
