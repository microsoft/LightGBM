{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "\n",
    "1. Download the data from https://www.kaggle.com/whitebird/ieee-internal-blend into folder “input”. \n",
    "2. Generate the features：  \n",
    "  python f3deepwalk.py  \n",
    "  python fdkey.py  \n",
    "  python feV307.py  \n",
    "  python fiyu.py  \n",
    "3. Run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random,math\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression \n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "from collections import Counter\n",
    "from math import log2,log10\n",
    "from sklearn.model_selection import KFold,TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def entropy(pr):\n",
    "    total = len(pr)\n",
    "    pr = Counter(pr)\n",
    "    log2 = math.log2\n",
    "    ent = 0\n",
    "    for i in pr:\n",
    "        p = float(pr[i]) / total\n",
    "        ent += (-p) * log2(p)\n",
    "    return ent\n",
    "import lightgbm as lgb\n",
    "def metric(true,pred):\n",
    "    thre = 0.2\n",
    "    pred = (pred > thre).astype(int)\n",
    "    p = np.sum(pred*true)/(np.sum(pred) + 0.01)\n",
    "    r = np.sum(pred*true)/(np.sum(true) + 0.01)\n",
    "    return p,r,2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('./input/train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('./input/test_transaction.csv', index_col='TransactionID')\n",
    "train_identity = pd.read_csv('./input/train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('./input/test_identity.csv', index_col='TransactionID')\n",
    "sample_submission = pd.read_csv('./input/sample_submission.csv', index_col='TransactionID')\n",
    "\n",
    "train_f5 = pd.read_csv('./input/fd_train4.csv', index_col='TransactionID')\n",
    "test_f5 = pd.read_csv('./input/fd_test4.csv', index_col='TransactionID')\n",
    "train_transaction = train_transaction.merge(train_f5, how='left', left_index=True, right_index=True)\n",
    "test_transaction = test_transaction.merge(test_f5, how='left', left_index=True, right_index=True)\n",
    "\n",
    "train_f5 = pd.read_csv('./input/fe_train3.csv', index_col='TransactionID')\n",
    "test_f5 = pd.read_csv('./input/fe_test3.csv', index_col='TransactionID')\n",
    "train_transaction = train_transaction.merge(train_f5, how='left', left_index=True, right_index=True)\n",
    "test_transaction = test_transaction.merge(test_f5, how='left', left_index=True, right_index=True)\n",
    "\n",
    "train_f5 = pd.read_csv('./input/fi_train4.csv', index_col='TransactionID')\n",
    "test_f5 = pd.read_csv('./input/fi_test4.csv', index_col='TransactionID')\n",
    "train_transaction = train_transaction.merge(train_f5, how='left', left_index=True, right_index=True)\n",
    "test_transaction = test_transaction.merge(test_f5, how='left', left_index=True, right_index=True)\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isFraud_s1', 'isFraud_s1_1', 'isFraud_s2', 'isFraud_s3', 'isFraud_s4', 'isFraud_s5', 'isFraud_s5_1']\n",
      "Memory usage of dataframe is 2840.42 MB\n",
      "Memory usage after optimization is: 856.33 MB\n",
      "Decreased by 69.9%\n"
     ]
    }
   ],
   "source": [
    "train_transaction['TransactionDT2'] = train_transaction['TransactionDT'].map(lambda x:(x//(3600*24*7)))\n",
    "test_transaction['TransactionDT2'] = test_transaction['TransactionDT'].map(lambda x:(x//(3600*24*7)))\n",
    "train_transaction['hour'] = train_transaction['TransactionDT'].map(lambda x:(x//3600+22)%24)\n",
    "test_transaction['hour'] = test_transaction['TransactionDT'].map(lambda x:(x//3600+22)%24)\n",
    "train_transaction['weekday'] = train_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)\n",
    "test_transaction['weekday'] = test_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)\n",
    "train_transaction['TransactionAmt_decimal'] = ((train_transaction['TransactionAmt'] - train_transaction['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test_transaction['TransactionAmt_decimal'] = ((test_transaction['TransactionAmt'] - test_transaction['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "train_test = train_transaction.append(test_transaction)\n",
    "for col in [[\"card1\",\"addr1\"],[\"card2\",\"addr1\"],[\"card1\",\"card2\"]]:\n",
    "    train_transaction[\"_\".join(col)] = train_transaction[col[0]].fillna(-1).map(str) + \"_\" + train_transaction[col[1]].fillna(-1).map(str)\n",
    "    test_transaction[\"_\".join(col)] = test_transaction[col[0]].fillna(-1).map(str) + \"_\" + test_transaction[col[1]].fillna(-1).map(str)\n",
    "    \n",
    "train_test = train_transaction.append(test_transaction)\n",
    "\n",
    "\n",
    "for col in [\"card1\",\"card1_card2\",\"card2_addr1\"]:\n",
    "    col_count = train_test.groupby(col)['TransactionAmt'].mean()\n",
    "    train_transaction[col+'_amtcount'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_amtcount'] = test_transaction[col].map(col_count)\n",
    "\n",
    "for col in [[\"card2\",\"addr1\"],[\"card1\",\"card2\"],[\"card1\",\"addr1\"]]:\n",
    "    col_count = train_transaction.groupby(col[0])[col[1]].apply(entropy)\n",
    "    train_transaction['en_' + col[0] +col[1] + '_count'] = train_transaction[col[0]].map(col_count)\n",
    "    col_count = test_transaction.groupby(col[0])[col[1]].apply(entropy)\n",
    "    test_transaction['en_' + col[0] +col[1] + '_count'] = test_transaction[col[0]].map(col_count)  \n",
    "    del train_transaction[\"_\".join(col)],test_transaction[\"_\".join(col)]\n",
    "    \n",
    "for col in \"ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,P_emaildomain,R_emaildomain,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,M1,M2,M3,M4,M5,M6,M7,M8,M9\".split(\",\"):\n",
    "    col_count = train_test.groupby(col)['TransactionDT'].count()\n",
    "    train_transaction[col+'_count'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_count'] = test_transaction[col].map(col_count)\n",
    "    \n",
    "for col in \"card1,card2,card3,card4,card5,addr1\".split(\",\"):\n",
    "    col_count = train_test.groupby(col)['TransactionAmt'].mean()\n",
    "    train_transaction[col+'_amtcount'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_amtcount'] = test_transaction[col].map(col_count)\n",
    "    col_count = train_test.groupby(col)['TransactionAmt'].std()\n",
    "    train_transaction[col+'_amtscount'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_amtscount'] = test_transaction[col].map(col_count)\n",
    "    \n",
    "    for col2 in \"C5,C8\".split(','):\n",
    "        col_count1 = train_test[train_test[col2] == 0].groupby(col)[col2].count()\n",
    "        col_count2 = train_test[train_test[col2] != 0].groupby(col)[col2].count()\n",
    "        train_transaction[col+'_'+col2+'count'] = train_transaction[col].map(col_count2) / (train_transaction[col].map(col_count1) + 0.01)\n",
    "        test_transaction[col+'_'+col2+'count'] = test_transaction[col].map(col_count2) / (test_transaction[col].map(col_count1) + 0.01)\n",
    "    for col2 in \"C13\".split(','):\n",
    "        col_count1 = train_test[train_test[col2] == 1].groupby(col)[col2].count()\n",
    "        col_count2 = train_test[train_test[col2] != 1].groupby(col)[col2].count()\n",
    "        train_transaction[col+'_'+col2+'count'] = train_transaction[col].map(col_count2) / (train_transaction[col].map(col_count1) + 0.01)\n",
    "        test_transaction[col+'_'+col2+'count'] = test_transaction[col].map(col_count2) / (test_transaction[col].map(col_count1) + 0.01)\n",
    "        \n",
    "train_transaction['TransactionAmt_to_mean_card1'] = train_transaction['TransactionAmt'] / train_transaction.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train_transaction['TransactionAmt_to_mean_card4'] = train_transaction['TransactionAmt'] / train_transaction.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train_transaction['TransactionAmt_to_std_card1'] = train_transaction['TransactionAmt'] / train_transaction.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train_transaction['TransactionAmt_to_std_card4'] = train_transaction['TransactionAmt'] / train_transaction.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "test_transaction['TransactionAmt_to_mean_card1'] = test_transaction['TransactionAmt'] / test_transaction.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test_transaction['TransactionAmt_to_mean_card4'] = test_transaction['TransactionAmt'] / test_transaction.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test_transaction['TransactionAmt_to_std_card1'] = test_transaction['TransactionAmt'] / test_transaction.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test_transaction['TransactionAmt_to_std_card4'] = test_transaction['TransactionAmt'] / test_transaction.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "train_transaction['D15_to_mean_card1'] = train_transaction['D15'] / train_transaction.groupby(['card1'])['D15'].transform('mean')\n",
    "train_transaction['D15_to_mean_card4'] = train_transaction['D15'] / train_transaction.groupby(['card4'])['D15'].transform('mean')\n",
    "train_transaction['D15_to_std_card1'] = train_transaction['D15'] / train_transaction.groupby(['card1'])['D15'].transform('std')\n",
    "train_transaction['D15_to_std_card4'] = train_transaction['D15'] / train_transaction.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test_transaction['D15_to_mean_card1'] = test_transaction['D15'] / test_transaction.groupby(['card1'])['D15'].transform('mean')\n",
    "test_transaction['D15_to_mean_card4'] = test_transaction['D15'] / test_transaction.groupby(['card4'])['D15'].transform('mean')\n",
    "test_transaction['D15_to_std_card1'] = test_transaction['D15'] / test_transaction.groupby(['card1'])['D15'].transform('std')\n",
    "test_transaction['D15_to_std_card4'] = test_transaction['D15'] / test_transaction.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "train_transaction['D15_to_mean_addr1'] = train_transaction['D15'] / train_transaction.groupby(['addr1'])['D15'].transform('mean')\n",
    "train_transaction['D15_to_std_addr1'] = train_transaction['D15'] / train_transaction.groupby(['addr1'])['D15'].transform('std')\n",
    "\n",
    "test_transaction['D15_to_mean_addr1'] = test_transaction['D15'] / test_transaction.groupby(['addr1'])['D15'].transform('mean')\n",
    "test_transaction['D15_to_std_addr1'] = test_transaction['D15'] / test_transaction.groupby(['addr1'])['D15'].transform('std')\n",
    "\n",
    "train_transaction['uid'] = train_transaction['card1'].astype(str)+'_'+train_transaction['card2'].astype(str)+'_'+train_transaction['card3'].astype(str)+'_'+train_transaction['card4'].astype(str)\n",
    "test_transaction['uid'] = test_transaction['card1'].astype(str)+'_'+test_transaction['card2'].astype(str)+'_'+test_transaction['card3'].astype(str)+'_'+test_transaction['card4'].astype(str)\n",
    "\n",
    "train_transaction['uid2'] = train_transaction['uid'].astype(str)+'_'+train_transaction['addr1'].astype(str)+'_'+train_transaction['addr2'].astype(str)\n",
    "test_transaction['uid2'] = test_transaction['uid'].astype(str)+'_'+test_transaction['addr1'].astype(str)+'_'+test_transaction['addr2'].astype(str)\n",
    "\n",
    "train_transaction['temp'] = train_transaction['TransactionDT2'].astype(str) + train_transaction['uid2'].astype(str) + train_transaction['TransactionAmt'].astype(str)\n",
    "test_transaction['temp'] = test_transaction['TransactionDT2'].astype(str) + test_transaction['uid2'].astype(str) + test_transaction['TransactionAmt'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_transaction['D16'] = train_transaction['D15'] - train_transaction['TransactionDT'].map(lambda x:(x//(3600*24)))\n",
    "test_transaction['D16'] = test_transaction['D15'] - test_transaction['TransactionDT'].map(lambda x:(x//(3600*24)))\n",
    "\n",
    "for col in \"D1,D2,D3,D4,D10\".split(','):\n",
    "    train_transaction[col + \"_day\"] = train_transaction[col] - train_transaction['TransactionDT'].map(lambda x:(x//(3600*24)))\n",
    "    test_transaction[col + \"_day\"] = test_transaction[col] - test_transaction['TransactionDT'].map(lambda x:(x//(3600*24)))\n",
    "    \n",
    "\n",
    "\n",
    "col_del_oof = []    \n",
    "col_del_amt = []\n",
    "for col in [['TransactionDT2','uid2','TransactionAmt']]: \n",
    "    col_count1 = train_transaction.groupby('temp')['isFraud'].sum()\n",
    "    train_transaction['isFraud_s1'] = train_transaction['temp'].map(col_count1) - train_transaction['isFraud']\n",
    "    col_count1 = train_transaction.groupby('temp')['isFraud'].count()\n",
    "    train_transaction['isFraud_s1_1'] = (train_transaction['isFraud_s1'])/(train_transaction['temp'].map(col_count1) - 0.99999)\n",
    "    \n",
    "    \n",
    "    train_transaction[\"_\".join(col)+'_hourmean'] = train_transaction.groupby('temp')['hour'].transform('mean')\n",
    "    test_transaction[\"_\".join(col)+'_hourmean'] = test_transaction.groupby('temp')['hour'].transform('mean')\n",
    "    \n",
    "    train_transaction['TransactionAmt_daysum'] = train_transaction.groupby('temp')['TransactionAmt'].transform('sum')\n",
    "    test_transaction['TransactionAmt_daysum'] = test_transaction.groupby('temp')['TransactionAmt'].transform('sum')\n",
    "    col_del_amt.append('TransactionAmt_daysum')\n",
    "    col_del_amt.append('TransactionAmt_ukeyen')\n",
    "    for col2 in \"C8,C13,D15\".split(','):\n",
    "        col_count1 = train_transaction[train_transaction[col2] == 0].groupby('temp')[col2].count()\n",
    "        train_transaction[\"_\".join(col)+'_'+col2+'count'] = (train_transaction['temp'].map(col_count1) /\n",
    "                                                             train_transaction.fillna(-1).groupby('temp')['TransactionAmt'].transform('count'))\n",
    "        col_count1 = test_transaction[test_transaction[col2] == 0].groupby('temp')[col2].count()\n",
    "        test_transaction[\"_\".join(col)+'_'+col2+'count'] = (test_transaction['temp'].map(col_count1)/\n",
    "                                                             test_transaction.fillna(-1).groupby('temp')['TransactionAmt'].transform('count'))\n",
    "        col_del_amt.append(\"_\".join(col)+'_'+col2+'count')\n",
    "\n",
    "    for col2 in \"D1_day,D4_day,D15,D16\".split(','):\n",
    "        train_transaction[\"_\".join(col)+'_'+col2+'mcount'] = ( \n",
    "                                                             train_transaction.groupby('temp')[col2].transform('mean'))\n",
    "        test_transaction[\"_\".join(col)+'_'+col2+'mcount'] = ( \n",
    "                                                             test_transaction.groupby('temp')[col2].transform('mean'))\n",
    "        col_del_amt.append(\"_\".join(col)+'_'+col2+'mcount')\n",
    "    for col2 in \"C1,C5,C8,D1,D4_day,D15,D16,V307,V310,V127\".split(','):\n",
    "        train_transaction[\"_\".join(col)+'_'+col2+'scount'] = (\n",
    "                                                             train_transaction.groupby('temp')[col2].transform('std'))\n",
    "        test_transaction[\"_\".join(col)+'_'+col2+'scount'] = (\n",
    "                                                             test_transaction.groupby('temp')[col2].transform('std'))\n",
    "        col_del_amt.append(\"_\".join(col)+'_'+col2+'scount')\n",
    "        \n",
    "# id\n",
    "col_del_ukey2 = []\n",
    "for col in [['tempkey']]: \n",
    "    col_count1 = train_transaction.groupby('tempkey')['isFraud'].sum()\n",
    "    train_transaction['isFraud_s2'] = train_transaction['tempkey'].map(col_count1) - train_transaction['isFraud']\n",
    "    \n",
    "    train_transaction[\"_\".join(col)+'_hourmean'] = train_transaction.groupby('tempkey')['hour'].transform('mean')\n",
    "    test_transaction[\"_\".join(col)+'_hourmean'] = test_transaction.groupby('tempkey')['hour'].transform('mean')\n",
    "    \n",
    "    train_transaction['TransactionAmt_ukeycount'] = train_transaction.groupby('ukey')['TransactionAmt'].transform('count')\n",
    "    test_transaction['TransactionAmt_ukeycount'] = test_transaction.groupby('ukey')['TransactionAmt'].transform('count')\n",
    "    col_del_ukey2.append('TransactionAmt_ukeysum')\n",
    "    \n",
    "    col_count = train_transaction.groupby(col[0])['card1'].apply(entropy)\n",
    "    train_transaction['en_' + col[0] +'card1' + '_count'] = train_transaction[col[0]].map(col_count)\n",
    "    col_count = test_transaction.groupby(col[0])['card1'].apply(entropy)\n",
    "    test_transaction['en_' + col[0] +'card1' + '_count'] = test_transaction[col[0]].map(col_count) \n",
    "    col_del_ukey2.append('en_' + col[0] +'card2' + '_count')\n",
    "    \n",
    "    col_count = train_transaction.groupby(col[0])['card2'].apply(entropy)\n",
    "    train_transaction['en_' + col[0] +'card2' + '_count'] = train_transaction[col[0]].map(col_count)\n",
    "    col_count = test_transaction.groupby(col[0])['card2'].apply(entropy)\n",
    "    test_transaction['en_' + col[0] +'card2' + '_count'] = test_transaction[col[0]].map(col_count)    \n",
    "    col_del_ukey2.append('en_' + col[0] +'card2' + '_count')\n",
    "    \n",
    "    \n",
    "# V307\n",
    "col_del_ukey = []\n",
    "for col in [['ukey']]: \n",
    "    col_count1 = train_transaction.groupby('ukey')['isFraud'].sum()\n",
    "    train_transaction['isFraud_s3'] = train_transaction['ukey'].map(col_count1) - train_transaction['isFraud']\n",
    "    \n",
    "    train_transaction['TransactionAmt_ukeysum'] = train_transaction.groupby('ukey')['TransactionAmt'].transform('sum')\n",
    "    test_transaction['TransactionAmt_ukeysum'] = test_transaction.groupby('ukey')['TransactionAmt'].transform('sum')\n",
    "    train_transaction['TransactionAmt_ukeystd'] = train_transaction.groupby('ukey')['TransactionAmt'].transform('std')\n",
    "    test_transaction['TransactionAmt_ukeystd'] = test_transaction.groupby('ukey')['TransactionAmt'].transform('std')\n",
    "    col_del_ukey.append('TransactionAmt_ukeysum')\n",
    "    col_del_ukey.append('TransactionAmt_ukeystd')\n",
    "    \n",
    "    for col2 in \"C3,C5,C7,C13,D1,D15\".split(','):\n",
    "        col_count1 = train_transaction[train_transaction[col2] == 0].groupby('ukey')[col2].count()\n",
    "        train_transaction[\"_\".join(col)+'_'+col2+'count'] = (train_transaction['ukey'].map(col_count1) /\n",
    "                                                             train_transaction.groupby(col)['TransactionAmt'].transform('count'))\n",
    "        col_count1 = test_transaction[test_transaction[col2] == 0].groupby('ukey')[col2].count()\n",
    "        test_transaction[\"_\".join(col)+'_'+col2+'count'] = (test_transaction['ukey'].map(col_count1)/\n",
    "                                                             test_transaction.groupby(col)['TransactionAmt'].transform('count'))\n",
    "        col_del_ukey.append(\"_\".join(col)+'_'+col2+'count')\n",
    "        \n",
    "    for col2 in \"C1,C4,C13,D10_day,D4_day,D16\".split(','):\n",
    "        train_transaction[\"_\".join(col)+'_'+col2+'scount'] = (\n",
    "                                                             train_transaction.groupby(col)[col2].transform('std'))\n",
    "        test_transaction[\"_\".join(col)+'_'+col2+'scount'] = (\n",
    "                                                             test_transaction.groupby(col)[col2].transform('std'))\n",
    "        col_del_ukey.append(\"_\".join(col)+'_'+col2+'scount')\n",
    "        \n",
    "\n",
    "train_transaction['TransactionDT3'] = train_transaction['TransactionDT'].map(lambda x:(x//(3600*24)))\n",
    "test_transaction['TransactionDT3'] = test_transaction['TransactionDT'].map(lambda x:(x//(3600*24)))\n",
    "train_transaction['uid2'] = train_transaction['uid'].astype(str)+'_'+train_transaction['addr1'].astype(str)+'_'+train_transaction['P_emaildomain'].astype(str)\n",
    "test_transaction['uid2'] = test_transaction['uid'].astype(str)+'_'+test_transaction['addr1'].astype(str)+'_'+test_transaction['P_emaildomain'].astype(str)\n",
    "\n",
    "train_transaction['temp'] = train_transaction['TransactionDT3'].astype(str) + train_transaction['uid2'].astype(str) \n",
    "test_transaction['temp'] = test_transaction['TransactionDT3'].astype(str) + test_transaction['uid2'].astype(str) \n",
    "\n",
    "\n",
    "\n",
    "train_test = train_transaction.append(test_transaction)\n",
    "d_cols=['D1_day']\n",
    "for i in d_cols:\n",
    "    train_test[str(i)+'_mean'] = train_test[i]/train_test.groupby('uid2')[i].transform('mean')\n",
    "    train_test[str(i)+'_std']  = train_test[i]/train_test.groupby('uid2')[i].transform('std')\n",
    "    train_transaction[str(i)+'_mean'] = train_test.loc[train_transaction.index,str(i)+'_mean']\n",
    "    train_transaction[str(i)+'_std'] = train_test.loc[train_transaction.index,str(i)+'_std']\n",
    "    test_transaction[str(i)+'_mean'] = train_test.loc[test_transaction.index,str(i)+'_mean']\n",
    "    test_transaction[str(i)+'_std']  = train_test.loc[test_transaction.index,str(i)+'_std']\n",
    "\n",
    "for col in [['card123456_add1_D15_series']]: \n",
    "    col_count1 = train_transaction.groupby('card123456_add1_D15_series')['isFraud'].sum()\n",
    "    train_transaction['isFraud_s4'] = train_transaction['card123456_add1_D15_series'].map(col_count1) - train_transaction['isFraud']\n",
    "    \n",
    "train_transaction['temp'] = train_transaction['TransactionDT2'].astype(str) + train_transaction['TransactionAmt'].astype(str)\n",
    "test_transaction['temp'] = test_transaction['TransactionDT2'].astype(str) + test_transaction['TransactionAmt'].astype(str)\n",
    "    \n",
    "for col in [['TransactionDT2','TransactionAmt']]: \n",
    "    col_count1 = train_transaction.groupby('temp')['isFraud'].sum()\n",
    "    train_transaction['isFraud_s5'] = train_transaction['temp'].map(col_count1) - train_transaction['isFraud']\n",
    "    col_count1 = train_transaction.groupby('temp')['isFraud'].count()\n",
    "    train_transaction['isFraud_s5_1'] = (train_transaction['isFraud_s5'])/(train_transaction['temp'].map(col_count1) - 0.99999)\n",
    "    \n",
    "    \n",
    "del train_transaction['tempkey'],test_transaction['tempkey']\n",
    "del train_transaction['temp'],test_transaction['temp']\n",
    "del train_transaction['uid'],test_transaction['uid']\n",
    "del train_transaction['uid2'],test_transaction['uid2']\n",
    "\n",
    "del train_transaction['ukey'],test_transaction['ukey']\n",
    "del train_transaction['TransactionDT3'],test_transaction['TransactionDT3']\n",
    "\n",
    "train_test['card123456_D2_series_D15_max'] = train_test.groupby('card123456_add1_D15_series')['D3'].transform('max')\n",
    "train_test['card123456_D2_series_D15_min'] = train_test.groupby('card123456_add1_D15_series')['D3'].transform('min')\n",
    "train_test['card123456_D2_series_D15_std'] = train_test.groupby('card123456_add1_D15_series')['D3'].transform('std')\n",
    "\n",
    "train_transaction['card123456_D2_series_D15_max']       = train_test.loc[train_transaction.index,'card123456_D2_series_D15_max']\n",
    "test_transaction['card123456_D2_series_D15_max']       = train_test.loc[test_transaction.index,'card123456_D2_series_D15_max']\n",
    "\n",
    "train_transaction['card123456_D2_series_D15_min']       = train_test.loc[train_transaction.index,'card123456_D2_series_D15_min']\n",
    "test_transaction['card123456_D2_series_D15_min']       = train_test.loc[test_transaction.index,'card123456_D2_series_D15_min']\n",
    "\n",
    "train_transaction['card123456_D2_series_D15_std']       = train_test.loc[train_transaction.index,'card123456_D2_series_D15_std']\n",
    "test_transaction['card123456_D2_series_D15_std']       = train_test.loc[test_transaction.index,'card123456_D2_series_D15_std']\n",
    "\n",
    "del train_transaction['card123456_add1_D2_series'],test_transaction['card123456_add1_D2_series']\n",
    "del train_transaction['card123456_add1_D15_series'],test_transaction['card123456_add1_D15_series']\n",
    "\n",
    "for col in \"C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14\".split(\",\"):\n",
    "    col_count = train_test.fillna(-1).groupby(col)['TransactionDT'].count()\n",
    "    minnum = col_count[col_count == 1].index.min()\n",
    "    train_transaction[col] = train_transaction[col].fillna(-1).map(lambda x:minnum if x >= minnum else x)\n",
    "    test_transaction[col] = test_transaction[col].fillna(-1).map(lambda x:minnum if x >= minnum  else x)\n",
    "\n",
    "col_del3 = []\n",
    "for col in \"D1,D2,D3,D4,D5,D6,D7,D8,D10,D11,D12,D13,D14,D15\".split(\",\"):\n",
    "    df = train_test[['TransactionDT',col]]\n",
    "    df = df[~df[col].isna()][df[col]>50.0]\n",
    "    x = np.asarray(df[['TransactionDT']])*0.0001\n",
    "    y = np.asarray(df[[col]])\n",
    "    reg = LinearRegression().fit(x, y)\n",
    "    train_transaction[col+'_fix'] = train_transaction[col].fillna(-1)*reg.intercept_[0]/(train_transaction['TransactionDT'].map(lambda x:x *0.0001 * reg.coef_[0][0]) + reg.intercept_[0])\n",
    "    train_transaction[col+'_fix'] = train_transaction[col+'_fix'].map(lambda x:-1 if x<0 else x)\n",
    "    test_transaction[col+'_fix'] = test_transaction[col].fillna(-1)*reg.intercept_[0]/(test_transaction['TransactionDT'].map(lambda x:x *0.0001 * reg.coef_[0][0]) + reg.intercept_[0])\n",
    "    test_transaction[col+'_fix'] = test_transaction[col+'_fix'].map(lambda x:-1 if x<0 else x)\n",
    "    col_del3.append(col+'_fix')\n",
    "    \n",
    "train_test = train_identity.append(test_identity).fillna(-1)    \n",
    "for col in \"id_01,id_02,id_04,id_05,id_08,id_09,id_10,id_12,id_13,id_14,id_15,id_16,id_17,id_18,id_19,id_20,id_21,id_22,id_27,id_28,id_29,id_30,id_31,id_32,id_33,id_34,DeviceType,DeviceInfo\".split(\",\"):\n",
    "    navalue = -1\n",
    "    if col in ['id_01','id_03','id_04','id_05','id_06','id_07','id_08','id_09','id_10']:\n",
    "        navalue = -999\n",
    "    col_count = train_test.fillna(navalue).groupby(col)['id_01'].count()\n",
    "    train_identity[col+'_count'] = train_identity[col].fillna(navalue).map(col_count)\n",
    "    test_identity[col+'_count'] = test_identity[col].fillna(navalue).map(col_count)\n",
    "\n",
    "train = train_transaction.merge(train_identity.fillna(-1) , how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity.fillna(-1) , how='left', left_index=True, right_index=True)\n",
    "train_test = train.append(test).fillna(-1)\n",
    "for col in \"card1,card2,card5\".split(\",\"):\n",
    "    \n",
    "    for col2 in \"id_01\".split(','):\n",
    "        col_count1 = train_test[train_test[col2].isna()].groupby(col)[col].count()\n",
    "        col_count2 = train_test.groupby(col)[col].count()\n",
    "        train_transaction[col+'_'+col2+'count'] = train_transaction[col].map(col_count1) / (train_transaction[col].map(col_count2) + 0.01)\n",
    "        test_transaction[col+'_'+col2+'count'] = test_transaction[col].map(col_count1) / (test_transaction[col].map(col_count2) + 0.01)\n",
    "\n",
    "del train_test,train,test\n",
    "\n",
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "test['isFraud'] = 0\n",
    "y_train = train['isFraud'].copy()\n",
    "y_test = test['isFraud'].copy()\n",
    "\n",
    "target_col = [x for x in train.columns.tolist() if x.startswith('isFraud_s') ]\n",
    "print(target_col)\n",
    "y_train_s = train[target_col].copy()\n",
    "y_test_s = test[['isFraud'] * len(target_col)].copy()\n",
    "\n",
    "del train_identity, test_identity\n",
    "del train_transaction, test_transaction\n",
    "del train['TransactionDT'],test['TransactionDT']\n",
    "del train['TransactionDT2'],test['TransactionDT2']\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.drop('isFraud', axis=1)\n",
    "\n",
    "X_train = X_train.drop(target_col,axis = 1)\n",
    "\n",
    "del test\n",
    "\n",
    "# Label Encoding\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n",
    "        if f in ['id_17','id_19','id_20','id_21','id_25','id_26']:\n",
    "            X_train[f] = X_train[f].fillna(-1)\n",
    "            X_test[f] = X_test[f].fillna(-1)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "        X_test[f] = lbl.transform(list(X_test[f].values))  \n",
    "        \n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "if not debug:\n",
    "    X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "\n",
    "if debug:\n",
    "    split_pos = X_train.shape[0]*4//5\n",
    "    y_test = y_train.iloc[split_pos:]\n",
    "    y_train = y_train.iloc[:split_pos]\n",
    "    X_test = X_train.iloc[split_pos:,:]\n",
    "    X_train = X_train.iloc[:split_pos,:]\n",
    "    \n",
    "    y_test_s = y_train_s.iloc[split_pos:]\n",
    "    y_train_s = y_train_s.iloc[:split_pos]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single task - LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{'boosting': 'gbdt', 'metric': 'auc', 'max_depth': 16, 'learning_rate': 0.03, 'bagging_fraction': 0.9, 'feature_fraction': 0.9, 'verbosity': -1, 'lambda_l1': 0.5, 'lambda_l2': 0.05, 'num_leaves': 500, 'min_child_weight': 0.1, 'min_data_in_leaf': 25, 'num_threads': 6, 'metric_freq': 10, 'data_random_seed': 17, 'objective': 'binary'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's auc: 0.942922\tvalid_1's auc: 0.907249\n",
      "[60]\tvalid_0's auc: 0.956821\tvalid_1's auc: 0.917659\n",
      "[90]\tvalid_0's auc: 0.965139\tvalid_1's auc: 0.926427\n",
      "[120]\tvalid_0's auc: 0.969578\tvalid_1's auc: 0.93253\n",
      "[150]\tvalid_0's auc: 0.971946\tvalid_1's auc: 0.935317\n",
      "[180]\tvalid_0's auc: 0.97354\tvalid_1's auc: 0.937167\n",
      "[210]\tvalid_0's auc: 0.974582\tvalid_1's auc: 0.938082\n",
      "[240]\tvalid_0's auc: 0.975385\tvalid_1's auc: 0.938556\n",
      "[270]\tvalid_0's auc: 0.976087\tvalid_1's auc: 0.938568\n",
      "[300]\tvalid_0's auc: 0.976488\tvalid_1's auc: 0.938633\n",
      "[330]\tvalid_0's auc: 0.976715\tvalid_1's auc: 0.938579\n",
      "[360]\tvalid_0's auc: 0.977021\tvalid_1's auc: 0.938501\n",
      "[390]\tvalid_0's auc: 0.977048\tvalid_1's auc: 0.938679\n",
      "[420]\tvalid_0's auc: 0.977112\tvalid_1's auc: 0.938728\n",
      "[450]\tvalid_0's auc: 0.977148\tvalid_1's auc: 0.938751\n",
      "[480]\tvalid_0's auc: 0.977155\tvalid_1's auc: 0.938731\n",
      "[510]\tvalid_0's auc: 0.977123\tvalid_1's auc: 0.938468\n",
      "[540]\tvalid_0's auc: 0.977044\tvalid_1's auc: 0.938348\n",
      "[570]\tvalid_0's auc: 0.976956\tvalid_1's auc: 0.938346\n",
      "[600]\tvalid_0's auc: 0.976826\tvalid_1's auc: 0.938328\n",
      "inner_predict 157478\n",
      "ROC AUC 0.976825874188662\n",
      "inner_predict 118108\n",
      "debug: 0.9383282327038023 0.08838374926742215 (0.7043879532099082, 0.5329711295001734, 0.6068059761703988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's auc: 0.941517\tvalid_1's auc: 0.903233\n",
      "[60]\tvalid_0's auc: 0.957602\tvalid_1's auc: 0.918348\n",
      "[90]\tvalid_0's auc: 0.965739\tvalid_1's auc: 0.927905\n",
      "[120]\tvalid_0's auc: 0.969918\tvalid_1's auc: 0.933978\n",
      "[150]\tvalid_0's auc: 0.971771\tvalid_1's auc: 0.936578\n",
      "[180]\tvalid_0's auc: 0.973442\tvalid_1's auc: 0.938302\n",
      "[210]\tvalid_0's auc: 0.974521\tvalid_1's auc: 0.938928\n",
      "[240]\tvalid_0's auc: 0.974953\tvalid_1's auc: 0.939199\n",
      "[270]\tvalid_0's auc: 0.975591\tvalid_1's auc: 0.939405\n",
      "[300]\tvalid_0's auc: 0.97602\tvalid_1's auc: 0.939742\n",
      "[330]\tvalid_0's auc: 0.976352\tvalid_1's auc: 0.939706\n",
      "[360]\tvalid_0's auc: 0.976506\tvalid_1's auc: 0.939846\n",
      "[390]\tvalid_0's auc: 0.976776\tvalid_1's auc: 0.939866\n",
      "[420]\tvalid_0's auc: 0.976871\tvalid_1's auc: 0.940117\n",
      "[450]\tvalid_0's auc: 0.97691\tvalid_1's auc: 0.940297\n",
      "[480]\tvalid_0's auc: 0.976985\tvalid_1's auc: 0.940462\n",
      "[510]\tvalid_0's auc: 0.977065\tvalid_1's auc: 0.940607\n",
      "[540]\tvalid_0's auc: 0.977076\tvalid_1's auc: 0.940718\n",
      "[570]\tvalid_0's auc: 0.977185\tvalid_1's auc: 0.940821\n",
      "[600]\tvalid_0's auc: 0.977157\tvalid_1's auc: 0.940839\n",
      "inner_predict 157477\n",
      "ROC AUC 0.9771569654469918\n",
      "inner_predict 118108\n",
      "debug: 0.9408392752886924 0.08942492054375245 (0.7171159381495764, 0.5339553790468035, 0.6121280334893272)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's auc: 0.945137\tvalid_1's auc: 0.908381\n",
      "[60]\tvalid_0's auc: 0.957698\tvalid_1's auc: 0.919396\n",
      "[90]\tvalid_0's auc: 0.965787\tvalid_1's auc: 0.927053\n",
      "[120]\tvalid_0's auc: 0.96973\tvalid_1's auc: 0.931029\n",
      "[150]\tvalid_0's auc: 0.971937\tvalid_1's auc: 0.933015\n",
      "[180]\tvalid_0's auc: 0.973336\tvalid_1's auc: 0.934318\n",
      "[210]\tvalid_0's auc: 0.974355\tvalid_1's auc: 0.93499\n",
      "[240]\tvalid_0's auc: 0.975213\tvalid_1's auc: 0.93542\n",
      "[270]\tvalid_0's auc: 0.975943\tvalid_1's auc: 0.935464\n",
      "[300]\tvalid_0's auc: 0.97645\tvalid_1's auc: 0.935679\n",
      "[330]\tvalid_0's auc: 0.976873\tvalid_1's auc: 0.935797\n",
      "[360]\tvalid_0's auc: 0.977212\tvalid_1's auc: 0.935884\n",
      "[390]\tvalid_0's auc: 0.977532\tvalid_1's auc: 0.93606\n",
      "[420]\tvalid_0's auc: 0.977704\tvalid_1's auc: 0.936244\n",
      "[450]\tvalid_0's auc: 0.977977\tvalid_1's auc: 0.936508\n",
      "[480]\tvalid_0's auc: 0.978039\tvalid_1's auc: 0.936491\n",
      "[510]\tvalid_0's auc: 0.978184\tvalid_1's auc: 0.936532\n",
      "[540]\tvalid_0's auc: 0.978241\tvalid_1's auc: 0.936653\n",
      "[570]\tvalid_0's auc: 0.978281\tvalid_1's auc: 0.936857\n",
      "[600]\tvalid_0's auc: 0.978302\tvalid_1's auc: 0.936957\n",
      "inner_predict 157477\n",
      "ROC AUC 0.978302250744647\n",
      "inner_predict 118108\n",
      "debug: 0.9369565788877728 0.08946408226270271 (0.7174746469295435, 0.5374002524600087, 0.6145171229118657)\n",
      "debug: 0.9442728771696625 0.08561792541562696 (0.7154395744915037, 0.543797874513104, 0.6179208222540968)\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in X_train.columns ]  \n",
    "cate = []\n",
    "print(cate)\n",
    "params = {\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'auc',\n",
    "          'max_depth': 16,\n",
    "          'learning_rate': 0.03,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'feature_fraction': 0.9,\n",
    "          'verbosity': -1,\n",
    "          'lambda_l1': 0.5,\n",
    "          'lambda_l2': 0.05,\n",
    "          'num_leaves': 500,\n",
    "          'min_child_weight': 0.1,\n",
    "          'min_data_in_leaf': 25,\n",
    "          \"num_threads\":6,\n",
    "          'metric_freq':10,\n",
    "          'data_random_seed': 17,\n",
    "         'objective':'binary'}\n",
    "print(params)\n",
    "early_stop = 500\n",
    "verbose_eval = 30\n",
    "num_rounds = 600\n",
    "# \n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_singlelgb = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "    X_tr, X_vl = X_train[features].iloc[tr_idx, :], X_train[features].iloc[val_idx, :]\n",
    "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    d_train = lgb.Dataset(X_tr, label=y_tr,categorical_feature = cate)\n",
    "    d_valid = lgb.Dataset(X_vl, label=y_vl,categorical_feature = cate)\n",
    "    watchlist = [d_valid]\n",
    "    if debug:\n",
    "        d_test = lgb.Dataset(X_test[features], label=y_test,categorical_feature = cate)\n",
    "        watchlist.append(d_test)\n",
    "    \n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval)\n",
    "    model.set_num_labels(1)\n",
    "        \n",
    "    y_pred_train = model.predict(X_vl)\n",
    "    y_oof[val_idx] = y_pred_train\n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "    \n",
    "    temp = model.predict(X_test[features])\n",
    "    y_singlelgb += temp / folds\n",
    "    \n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, temp),log_loss(y_test, temp),metric(y_test, temp))  \n",
    "    i+=1\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_singlelgb),log_loss(y_test, y_singlelgb),metric(y_test, y_singlelgb))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single task - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "\n",
    "\n",
    "features = [x for x in X_train.columns]\n",
    "print(len(features))\n",
    "cate = [x for x in features if (x == 'ProductCD' or x in ['card1','card2'] or  x.startswith(\"addr\") or \n",
    "                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") and not x == \"id_11\" \n",
    "       ]\n",
    "\n",
    "print(cate)\n",
    "verbose_eval = 30\n",
    "num_rounds = 700\n",
    "y_preds3_temp = np.zeros(X_test.shape[0])\n",
    "y_preds3_temp2 = np.zeros(X_test.shape[0])\n",
    "\n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed+1)\n",
    "y_preds3 = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "\n",
    "    \n",
    "    X_tr, X_vl = X_train[features].iloc[tr_idx, :].fillna(-999), X_train[features].iloc[val_idx, :].fillna(-999)\n",
    "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    model=cb.CatBoostClassifier(iterations=num_rounds,depth=15,learning_rate=0.04,loss_function='Logloss',eval_metric='Logloss'\n",
    "                                ,l2_leaf_reg=3.0\n",
    "                                                                ,task_type = \"CPU\"\n",
    "                               )\n",
    "    if debug:\n",
    "        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n",
    "    else:\n",
    "        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n",
    "    best_iter = model.get_best_iteration()\n",
    "    best_iter = 0\n",
    "    print(best_iter)\n",
    "    y_pred_train = model.predict_proba(X_vl,ntree_end = best_iter)[:,1]\n",
    "    y_oof[val_idx] = y_pred_train\n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "    \n",
    "    temp =  model.predict_proba(X_test[features].fillna(-999),ntree_end = best_iter)[:,1] \n",
    "    y_preds3 += temp/ folds\n",
    "    \n",
    "    \n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, temp),log_loss(y_test, temp))\n",
    "    i+=1\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds3),log_loss(y_test, y_preds3),metric(y_test, y_preds3))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single task - XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.977359673317878\n",
      "debug: 0.9389635681952566 0.08012012434578761 (0.677605283419376, 0.5435518121264465, 0.6032206356618359)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.9779645466176727\n",
      "debug: 0.9417379616587409 0.0814588393395007 (0.6901914734807199, 0.543797874513104, 0.6083110148334301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.9790168109097567\n",
      "debug: 0.9361365936655336 0.08196450129562 (0.6694666182329083, 0.5487191222462543, 0.6031085784757851)\n",
      "debug: 0.9441943410793652 0.07888473225127263 (0.6860938491382843, 0.5561009938459797, 0.6142956936784624)\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "X_test_pred = pd.DataFrame(index = X_test.index)\n",
    "X_train_pred = pd.DataFrame(index = X_train.index)\n",
    "i = 0\n",
    "params = {\n",
    "        \"n_estimators\":700,\n",
    "        \"max_depth\":15,\n",
    "        \"learning_rate\":0.03,\n",
    "        \"subsample\":0.9,\n",
    "        \"colsample_bytree\":0.7,\n",
    "        \"min_child_weight\":2.5,\n",
    "        \"tree_method\":'gpu_hist',\n",
    "        'reg_alpha' :0.5,\n",
    "        'reg_lambda' : 0.4,\n",
    "}\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "# for tr_idx, val_idx in folds_index:\n",
    "    \n",
    "    i+=1\n",
    "    clf = xgb.XGBClassifier(\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "    y_oof[val_idx] = y_pred_train\n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "    \n",
    "    temp = clf.predict_proba(X_test)[:,1]\n",
    "    y_preds+= temp / folds\n",
    "#     X_test_pred['pred'+str(i)] = clf.predict_proba(X_test)[:,1]\n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, temp),log_loss(y_test, temp),metric(y_test, temp))    \n",
    "    del X_tr,X_vl\n",
    "        \n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds),log_loss(y_test, y_preds),metric(y_test, y_preds))  \n",
    "\n",
    "del X_test_pred,X_train_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT-GBM  \n",
    "subtasklist:['isFraud_s1', 'isFraud_s1_1', 'isFraud_s2', 'isFraud_s3', 'isFraud_s4', 'isFraud_s5', 'isFraud_s5_1']  \n",
    "\n",
    " \n",
    "we use isFraud_s1 isFraud_s2 & isFraud_s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{'objective': 'custom', 'num_labels': 2, 'tree_learner': 'serial2', 'boosting': 'gbdt', 'max_depth': 16, 'learning_rate': 0.03, 'bagging_fraction': 0.9, 'feature_fraction': 0.9, 'verbosity': -1, 'lambda_l1': 0.5, 'lambda_l2': 0.05, 'num_leaves': 500, 'min_child_weight': 0.1, 'min_data_in_leaf': 25, 'num_threads': 18, 'metric_freq': 10, 'data_random_seed': 17}\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.928725\tvalid_1's self_metric: 0.897619\n",
      "[140]\tvalid_0's self_metric: 0.96086\tvalid_1's self_metric: 0.922505\n",
      "[210]\tvalid_0's self_metric: 0.972187\tvalid_1's self_metric: 0.935298\n",
      "[280]\tvalid_0's self_metric: 0.975295\tvalid_1's self_metric: 0.938757\n",
      "[350]\tvalid_0's self_metric: 0.976757\tvalid_1's self_metric: 0.940028\n",
      "[420]\tvalid_0's self_metric: 0.977116\tvalid_1's self_metric: 0.940089\n",
      "[490]\tvalid_0's self_metric: 0.977184\tvalid_1's self_metric: 0.940169\n",
      "inner_predict 314956\n",
      "ROC AUC 0.9771751736781917\n",
      "inner_predict 236216\n",
      "debug: 0.9401605501689223 0.7489290472487878 (0.8341691826150069, 0.4072332499181842, 0.54728654997834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.931197\tvalid_1's self_metric: 0.901185\n",
      "[140]\tvalid_0's self_metric: 0.962312\tvalid_1's self_metric: 0.922984\n",
      "[210]\tvalid_0's self_metric: 0.972969\tvalid_1's self_metric: 0.936495\n",
      "[280]\tvalid_0's self_metric: 0.975687\tvalid_1's self_metric: 0.939436\n",
      "[350]\tvalid_0's self_metric: 0.97684\tvalid_1's self_metric: 0.940041\n",
      "[420]\tvalid_0's self_metric: 0.977388\tvalid_1's self_metric: 0.9406\n",
      "[490]\tvalid_0's self_metric: 0.977461\tvalid_1's self_metric: 0.940955\n",
      "inner_predict 314954\n",
      "ROC AUC 0.9775020348682498\n",
      "inner_predict 236216\n",
      "debug: 0.9410025484534633 0.7534900856058854 (0.8467865073162147, 0.40255806457169147, 0.5456953112231113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.93374\tvalid_1's self_metric: 0.900957\n",
      "[140]\tvalid_0's self_metric: 0.962251\tvalid_1's self_metric: 0.922906\n",
      "[210]\tvalid_0's self_metric: 0.972871\tvalid_1's self_metric: 0.932115\n",
      "[280]\tvalid_0's self_metric: 0.975944\tvalid_1's self_metric: 0.935231\n",
      "[350]\tvalid_0's self_metric: 0.977591\tvalid_1's self_metric: 0.935995\n",
      "[420]\tvalid_0's self_metric: 0.97814\tvalid_1's self_metric: 0.936174\n",
      "[490]\tvalid_0's self_metric: 0.978548\tvalid_1's self_metric: 0.936704\n",
      "inner_predict 314954\n",
      "ROC AUC 0.9786004518936104\n",
      "inner_predict 236216\n",
      "debug: 0.9368506874815825 0.7489494401682065 (0.8512138350760234, 0.40403443889163654, 0.5479708060376904)\n",
      "debug: 0.9446678738203544 0.08598253775521543 (0.7214997623803178, 0.534201441433461, 0.6138820475553582)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.928177\tvalid_1's self_metric: 0.898302\n",
      "[140]\tvalid_0's self_metric: 0.960401\tvalid_1's self_metric: 0.92255\n",
      "[210]\tvalid_0's self_metric: 0.971493\tvalid_1's self_metric: 0.934022\n",
      "[280]\tvalid_0's self_metric: 0.97473\tvalid_1's self_metric: 0.93722\n",
      "[350]\tvalid_0's self_metric: 0.976423\tvalid_1's self_metric: 0.93785\n",
      "[420]\tvalid_0's self_metric: 0.976758\tvalid_1's self_metric: 0.938142\n",
      "[490]\tvalid_0's self_metric: 0.976634\tvalid_1's self_metric: 0.938433\n",
      "inner_predict 314956\n",
      "ROC AUC 0.9765716130223431\n",
      "inner_predict 236216\n",
      "debug: 0.9383387575475083 0.7498151207388 (0.8389566807445156, 0.3973907544518837, 0.5393202894630507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.930369\tvalid_1's self_metric: 0.899115\n",
      "[140]\tvalid_0's self_metric: 0.962331\tvalid_1's self_metric: 0.922318\n",
      "[210]\tvalid_0's self_metric: 0.972344\tvalid_1's self_metric: 0.934966\n",
      "[280]\tvalid_0's self_metric: 0.97545\tvalid_1's self_metric: 0.93799\n",
      "[350]\tvalid_0's self_metric: 0.976489\tvalid_1's self_metric: 0.939047\n",
      "[420]\tvalid_0's self_metric: 0.977033\tvalid_1's self_metric: 0.939606\n",
      "[490]\tvalid_0's self_metric: 0.977099\tvalid_1's self_metric: 0.940184\n",
      "inner_predict 314954\n",
      "ROC AUC 0.9770741793761524\n",
      "inner_predict 236216\n",
      "debug: 0.9402860478183995 0.7569123286809641 (0.8425399241922618, 0.39763681683854124, 0.5402857228829059)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.933784\tvalid_1's self_metric: 0.900006\n",
      "[140]\tvalid_0's self_metric: 0.962437\tvalid_1's self_metric: 0.92328\n",
      "[210]\tvalid_0's self_metric: 0.972813\tvalid_1's self_metric: 0.932536\n",
      "[280]\tvalid_0's self_metric: 0.976031\tvalid_1's self_metric: 0.93555\n",
      "[350]\tvalid_0's self_metric: 0.977426\tvalid_1's self_metric: 0.936187\n",
      "[420]\tvalid_0's self_metric: 0.978014\tvalid_1's self_metric: 0.937021\n",
      "[490]\tvalid_0's self_metric: 0.978266\tvalid_1's self_metric: 0.937358\n",
      "inner_predict 314954\n",
      "ROC AUC 0.9782544514448095\n",
      "inner_predict 236216\n",
      "debug: 0.9372856172621037 0.7496147117955603 (0.8466623248085907, 0.4062490003715542, 0.5490503855989837)\n",
      "debug: 0.9441210026824844 0.08647314253440228 (0.7225889614984667, 0.5351856909800911, 0.6149261664513247)\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.928808\tvalid_1's self_metric: 0.897218\n",
      "[140]\tvalid_0's self_metric: 0.961063\tvalid_1's self_metric: 0.922136\n",
      "[210]\tvalid_0's self_metric: 0.971745\tvalid_1's self_metric: 0.935092\n",
      "[280]\tvalid_0's self_metric: 0.975167\tvalid_1's self_metric: 0.938984\n",
      "[350]\tvalid_0's self_metric: 0.976837\tvalid_1's self_metric: 0.939459\n",
      "[420]\tvalid_0's self_metric: 0.977459\tvalid_1's self_metric: 0.939187\n",
      "[490]\tvalid_0's self_metric: 0.977331\tvalid_1's self_metric: 0.939678\n",
      "inner_predict 314956\n",
      "ROC AUC 0.9772796004389912\n",
      "inner_predict 236216\n",
      "debug: 0.9397198120900706 0.7446538765812342 (0.8501248055565604, 0.40477262605160913, 0.548422909075149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.931976\tvalid_1's self_metric: 0.899887\n",
      "[140]\tvalid_0's self_metric: 0.962791\tvalid_1's self_metric: 0.923174\n",
      "[210]\tvalid_0's self_metric: 0.972631\tvalid_1's self_metric: 0.935801\n",
      "[280]\tvalid_0's self_metric: 0.975462\tvalid_1's self_metric: 0.938751\n",
      "[350]\tvalid_0's self_metric: 0.976594\tvalid_1's self_metric: 0.939324\n",
      "[420]\tvalid_0's self_metric: 0.977138\tvalid_1's self_metric: 0.940054\n",
      "[490]\tvalid_0's self_metric: 0.977427\tvalid_1's self_metric: 0.940463\n",
      "inner_predict 314954\n",
      "ROC AUC 0.9774686553555838\n",
      "inner_predict 236216\n",
      "debug: 0.9405157582499585 0.7547084989532638 (0.8481034312937724, 0.40255806457169147, 0.5459684766611825)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.933177\tvalid_1's self_metric: 0.901068\n",
      "[140]\tvalid_0's self_metric: 0.96247\tvalid_1's self_metric: 0.922793\n",
      "[210]\tvalid_0's self_metric: 0.972961\tvalid_1's self_metric: 0.932958\n",
      "[280]\tvalid_0's self_metric: 0.975767\tvalid_1's self_metric: 0.935439\n",
      "[350]\tvalid_0's self_metric: 0.977345\tvalid_1's self_metric: 0.936405\n",
      "[420]\tvalid_0's self_metric: 0.97798\tvalid_1's self_metric: 0.937414\n",
      "[490]\tvalid_0's self_metric: 0.978336\tvalid_1's self_metric: 0.937911\n",
      "inner_predict 314954\n",
      "ROC AUC 0.9783372824741133\n",
      "inner_predict 236216\n",
      "debug: 0.9380239939509464 0.7449575766096953 (0.8473587862130516, 0.4111702481047044, 0.5536760978260509)\n",
      "debug: 0.9446403577621788 0.08593010744809629 (0.7201027591893587, 0.5393687515532688, 0.6167681013840705)\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in X_train.columns ]  \n",
    "cate = []\n",
    "print(cate)\n",
    "num_label = 2  \n",
    "params = {'objective': 'custom',\n",
    "          'num_labels':num_label, \n",
    "          'tree_learner': 'serial2',\n",
    "          'boosting': 'gbdt',\n",
    "          'max_depth': 16,\n",
    "          'learning_rate': 0.03,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'feature_fraction': 0.9,\n",
    "          'verbosity': -1,\n",
    "          'lambda_l1': 0.5,\n",
    "          'lambda_l2': 0.05,\n",
    "          'num_leaves': 500,\n",
    "          'min_child_weight': 0.1,\n",
    "          'min_data_in_leaf': 25,\n",
    "          \"num_threads\":18,\n",
    "          'metric_freq':10,\n",
    "          'data_random_seed': 17}\n",
    "print(params)\n",
    "early_stop = 500\n",
    "verbose_eval = 70\n",
    "num_rounds = 500\n",
    "# \n",
    "\n",
    "for target_col in [0,2,3]:\n",
    "    print(target_col)\n",
    "    folds = 3\n",
    "    kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "    y_preds22 = np.zeros(X_test.shape[0])\n",
    "    y_oof = np.zeros(X_train.shape[0])\n",
    "    i = 0\n",
    "    for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "\n",
    "        def self_metric(preds, train_data):\n",
    "            labels = train_data.get_label()\n",
    "            labels2 = labels.reshape((num_label,-1)).transpose()[:,0]\n",
    "            preds2 = preds.reshape((num_label,-1)).transpose()[:,0]\n",
    "            preds2 = 1. / (1. + np.exp(-preds2))\n",
    "            score = roc_auc_score(labels2, preds2)\n",
    "            return 'self_metric', score, False\n",
    "  \n",
    "\n",
    "        def mymse3(preds, train_data, ep = 0):\n",
    "            labels = train_data.get_label()\n",
    "            labels2 = labels.reshape((num_label,-1)).transpose()\n",
    "            preds2 = preds.reshape((num_label,-1)).transpose()\n",
    "\n",
    "            labels2 = np.clip(labels2,0,1)\n",
    "\n",
    "            preds3 = 1. / (1. + np.exp(-preds2))\n",
    "            grad2 = preds3 - labels2\n",
    "            hess2 = preds3 * (1. - preds3)\n",
    "\n",
    "            import random\n",
    "            beta = 0.2\n",
    "            w = np.array([1,0.1 * beta])\n",
    "            w2 = np.array([1.0,1.0])\n",
    "\n",
    "            grad = (grad2) * np.array(w)\n",
    "            grad = np.sum(grad,axis = 1)\n",
    "            grad2 = (grad2 * w2).transpose().reshape((-1))\n",
    "\n",
    "            hess = np.sum((hess2) * np.array(w),axis = 1)\n",
    "            return grad, hess, grad2, hess2 \n",
    "\n",
    "        X_tr, X_vl = X_train[features].iloc[tr_idx, :], X_train[features].iloc[val_idx, :]\n",
    "        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        target = [target_col]\n",
    "        y_tr2, y_vl2 = y_train_s.iloc[tr_idx, target], y_train_s.iloc[val_idx, target]\n",
    "        d_train = lgb.Dataset(X_tr, label=np.concatenate([y_tr.values.reshape((-1,1)),y_tr2.values],axis = 1),categorical_feature = cate)\n",
    "        d_valid = lgb.Dataset(X_vl, label=np.concatenate([y_vl.values.reshape((-1,1)),y_vl2.values],axis = 1),categorical_feature = cate)\n",
    "        watchlist = [d_valid]\n",
    "        if debug:\n",
    "            d_test = lgb.Dataset(X_test[features], label=np.concatenate([y_test.values.reshape((-1,1)),y_test_s.values[:,target]],axis = 1),categorical_feature = cate)\n",
    "            watchlist.append(d_test)\n",
    "\n",
    "\n",
    "        model = lgb.train(params,\n",
    "                          train_set=d_train,\n",
    "                          num_boost_round=num_rounds,\n",
    "                          valid_sets=watchlist,\n",
    "                          verbose_eval=verbose_eval,\n",
    "                         fobj = mymse3,\n",
    "                         feval = self_metric\n",
    "                         )\n",
    "        model.set_num_labels(num_label)\n",
    "\n",
    "        y_pred_train = model.predict(X_vl)[:,0]\n",
    "        y_oof[val_idx] = y_pred_train\n",
    "        print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "\n",
    "        temp = model.predict(X_test[features])[:,0]\n",
    "        y_preds22 += (1. / (1. + np.exp(-temp))) / folds\n",
    "        if debug:    \n",
    "            print(\"debug:\",roc_auc_score(y_test, temp),log_loss(y_test, temp),metric(y_test, temp))  \n",
    "        i+=1\n",
    "\n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, y_preds22),log_loss(y_test, y_preds22),metric(y_test, y_preds22))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{'objective': 'custom', 'num_labels': 3, 'tree_learner': 'serial2', 'boosting': 'gbdt', 'max_depth': 16, 'learning_rate': 0.03, 'bagging_fraction': 0.9, 'feature_fraction': 0.9, 'verbosity': -1, 'lambda_l1': 0.5, 'lambda_l2': 0.05, 'num_leaves': 500, 'min_child_weight': 0.1, 'min_data_in_leaf': 25, 'num_threads': 18, 'metric_freq': 10, 'data_random_seed': 17}\n",
      "[0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.929575\tvalid_1's self_metric: 0.898785\n",
      "[140]\tvalid_0's self_metric: 0.960401\tvalid_1's self_metric: 0.922081\n",
      "[210]\tvalid_0's self_metric: 0.972126\tvalid_1's self_metric: 0.934892\n",
      "[280]\tvalid_0's self_metric: 0.975215\tvalid_1's self_metric: 0.938789\n",
      "[350]\tvalid_0's self_metric: 0.97683\tvalid_1's self_metric: 0.939416\n",
      "[420]\tvalid_0's self_metric: 0.977576\tvalid_1's self_metric: 0.939339\n",
      "[490]\tvalid_0's self_metric: 0.977798\tvalid_1's self_metric: 0.938831\n",
      "[560]\tvalid_0's self_metric: 0.977809\tvalid_1's self_metric: 0.939252\n",
      "[630]\tvalid_0's self_metric: 0.977669\tvalid_1's self_metric: 0.939092\n",
      "[700]\tvalid_0's self_metric: 0.97751\tvalid_1's self_metric: 0.939082\n",
      "inner_predict 472434\n",
      "ROC AUC 0.9773984497173717\n",
      "inner_predict 354324\n",
      "debug: 0.9389769367749207 0.753980291838028 (0.8429114840272894, 0.40403443889163654, 0.5462390344676166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.931133\tvalid_1's self_metric: 0.900066\n",
      "[140]\tvalid_0's self_metric: 0.962371\tvalid_1's self_metric: 0.920611\n",
      "[210]\tvalid_0's self_metric: 0.973084\tvalid_1's self_metric: 0.934711\n",
      "[280]\tvalid_0's self_metric: 0.975877\tvalid_1's self_metric: 0.937978\n",
      "[350]\tvalid_0's self_metric: 0.977026\tvalid_1's self_metric: 0.938542\n",
      "[420]\tvalid_0's self_metric: 0.977808\tvalid_1's self_metric: 0.938837\n",
      "[490]\tvalid_0's self_metric: 0.978329\tvalid_1's self_metric: 0.938819\n",
      "[560]\tvalid_0's self_metric: 0.978644\tvalid_1's self_metric: 0.93865\n",
      "[630]\tvalid_0's self_metric: 0.978771\tvalid_1's self_metric: 0.93846\n",
      "[700]\tvalid_0's self_metric: 0.97871\tvalid_1's self_metric: 0.938487\n",
      "inner_predict 472431\n",
      "ROC AUC 0.9786912805865297\n",
      "inner_predict 354324\n",
      "debug: 0.9383381469425947 0.7592383247106337 (0.8422098178488472, 0.4005895654784314, 0.5429363250414372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.934287\tvalid_1's self_metric: 0.898836\n",
      "[140]\tvalid_0's self_metric: 0.962329\tvalid_1's self_metric: 0.92296\n",
      "[210]\tvalid_0's self_metric: 0.973126\tvalid_1's self_metric: 0.933164\n",
      "[280]\tvalid_0's self_metric: 0.976289\tvalid_1's self_metric: 0.935702\n",
      "[350]\tvalid_0's self_metric: 0.977764\tvalid_1's self_metric: 0.936453\n",
      "[420]\tvalid_0's self_metric: 0.978597\tvalid_1's self_metric: 0.93672\n",
      "[490]\tvalid_0's self_metric: 0.979156\tvalid_1's self_metric: 0.937004\n",
      "[560]\tvalid_0's self_metric: 0.979429\tvalid_1's self_metric: 0.937622\n",
      "[630]\tvalid_0's self_metric: 0.979475\tvalid_1's self_metric: 0.937628\n",
      "[700]\tvalid_0's self_metric: 0.979456\tvalid_1's self_metric: 0.937618\n",
      "inner_predict 472431\n",
      "ROC AUC 0.9795120099090322\n",
      "inner_predict 354324\n",
      "debug: 0.9375567733112817 0.7559501088650546 (0.8364609626157308, 0.40526475082492414, 0.5459952063808838)\n",
      "debug: 0.9437127474904697 0.09519729132918744 (0.7318061960977266, 0.5196837606206678, 0.6077680351998987)\n",
      "[2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.928235\tvalid_1's self_metric: 0.899576\n",
      "[140]\tvalid_0's self_metric: 0.960121\tvalid_1's self_metric: 0.922969\n",
      "[210]\tvalid_0's self_metric: 0.971851\tvalid_1's self_metric: 0.935324\n",
      "[280]\tvalid_0's self_metric: 0.975188\tvalid_1's self_metric: 0.93887\n",
      "[350]\tvalid_0's self_metric: 0.97648\tvalid_1's self_metric: 0.939665\n",
      "[420]\tvalid_0's self_metric: 0.977079\tvalid_1's self_metric: 0.939828\n",
      "[490]\tvalid_0's self_metric: 0.977294\tvalid_1's self_metric: 0.93976\n",
      "[560]\tvalid_0's self_metric: 0.976955\tvalid_1's self_metric: 0.939463\n",
      "[630]\tvalid_0's self_metric: 0.976855\tvalid_1's self_metric: 0.939638\n",
      "[700]\tvalid_0's self_metric: 0.976585\tvalid_1's self_metric: 0.939586\n",
      "inner_predict 472434\n",
      "ROC AUC 0.9764755532915975\n",
      "inner_predict 354324\n",
      "debug: 0.939636545429903 0.74341532485013 (0.847963632896975, 0.4158454334511972, 0.5580301864613292)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.930644\tvalid_1's self_metric: 0.898617\n",
      "[140]\tvalid_0's self_metric: 0.961677\tvalid_1's self_metric: 0.919977\n",
      "[210]\tvalid_0's self_metric: 0.972539\tvalid_1's self_metric: 0.933482\n",
      "[280]\tvalid_0's self_metric: 0.975742\tvalid_1's self_metric: 0.937939\n",
      "[350]\tvalid_0's self_metric: 0.976946\tvalid_1's self_metric: 0.939122\n",
      "[420]\tvalid_0's self_metric: 0.977521\tvalid_1's self_metric: 0.939446\n",
      "[490]\tvalid_0's self_metric: 0.977729\tvalid_1's self_metric: 0.940097\n",
      "[560]\tvalid_0's self_metric: 0.977762\tvalid_1's self_metric: 0.940474\n",
      "[630]\tvalid_0's self_metric: 0.977583\tvalid_1's self_metric: 0.940212\n",
      "[700]\tvalid_0's self_metric: 0.977395\tvalid_1's self_metric: 0.940247\n",
      "inner_predict 472431\n",
      "ROC AUC 0.9772746992506263\n",
      "inner_predict 354324\n",
      "debug: 0.9400957677924835 0.7558386804047539 (0.848149515603143, 0.4013277526384039, 0.544845348771175)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.933068\tvalid_1's self_metric: 0.89876\n",
      "[140]\tvalid_0's self_metric: 0.961933\tvalid_1's self_metric: 0.921531\n",
      "[210]\tvalid_0's self_metric: 0.972478\tvalid_1's self_metric: 0.932549\n",
      "[280]\tvalid_0's self_metric: 0.975746\tvalid_1's self_metric: 0.93495\n",
      "[350]\tvalid_0's self_metric: 0.977484\tvalid_1's self_metric: 0.935736\n",
      "[420]\tvalid_0's self_metric: 0.978174\tvalid_1's self_metric: 0.936397\n",
      "[490]\tvalid_0's self_metric: 0.978473\tvalid_1's self_metric: 0.937105\n",
      "[560]\tvalid_0's self_metric: 0.978715\tvalid_1's self_metric: 0.937522\n",
      "[630]\tvalid_0's self_metric: 0.978741\tvalid_1's self_metric: 0.937636\n",
      "[700]\tvalid_0's self_metric: 0.978754\tvalid_1's self_metric: 0.937587\n",
      "inner_predict 472431\n",
      "ROC AUC 0.9787324444431854\n",
      "inner_predict 354324\n",
      "debug: 0.9376791122130788 0.7513073977678643 (0.8368644602805037, 0.4077253746914993, 0.5483105615136945)\n",
      "debug: 0.9448312872300704 0.0948451539351626 (0.7358790086810996, 0.5258353202871056, 0.6133736699952067)\n",
      "[0, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.929973\tvalid_1's self_metric: 0.899998\n",
      "[140]\tvalid_0's self_metric: 0.960529\tvalid_1's self_metric: 0.922348\n",
      "[210]\tvalid_0's self_metric: 0.972099\tvalid_1's self_metric: 0.935328\n",
      "[280]\tvalid_0's self_metric: 0.975591\tvalid_1's self_metric: 0.939314\n",
      "[350]\tvalid_0's self_metric: 0.977092\tvalid_1's self_metric: 0.939774\n",
      "[420]\tvalid_0's self_metric: 0.97765\tvalid_1's self_metric: 0.939862\n",
      "[490]\tvalid_0's self_metric: 0.977777\tvalid_1's self_metric: 0.939614\n",
      "[560]\tvalid_0's self_metric: 0.977777\tvalid_1's self_metric: 0.939506\n",
      "[630]\tvalid_0's self_metric: 0.977818\tvalid_1's self_metric: 0.939498\n",
      "[700]\tvalid_0's self_metric: 0.977807\tvalid_1's self_metric: 0.939471\n",
      "inner_predict 472434\n",
      "ROC AUC 0.9778459757807737\n",
      "inner_predict 354324\n",
      "debug: 0.9394034367554503 0.7414958203293461 (0.8532537031621182, 0.40920174901144435, 0.5531330346481468)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.93208\tvalid_1's self_metric: 0.899621\n",
      "[140]\tvalid_0's self_metric: 0.962346\tvalid_1's self_metric: 0.921702\n",
      "[210]\tvalid_0's self_metric: 0.973262\tvalid_1's self_metric: 0.935268\n",
      "[280]\tvalid_0's self_metric: 0.976033\tvalid_1's self_metric: 0.938673\n",
      "[350]\tvalid_0's self_metric: 0.977202\tvalid_1's self_metric: 0.939775\n",
      "[420]\tvalid_0's self_metric: 0.978047\tvalid_1's self_metric: 0.940025\n",
      "[490]\tvalid_0's self_metric: 0.978553\tvalid_1's self_metric: 0.939872\n",
      "[560]\tvalid_0's self_metric: 0.97867\tvalid_1's self_metric: 0.939525\n",
      "[630]\tvalid_0's self_metric: 0.978637\tvalid_1's self_metric: 0.93924\n",
      "[700]\tvalid_0's self_metric: 0.978563\tvalid_1's self_metric: 0.939059\n",
      "inner_predict 472431\n",
      "ROC AUC 0.9785095781806656\n",
      "inner_predict 354324\n",
      "debug: 0.939171693850999 0.7614307214445439 (0.8473041029808335, 0.402804126958349, 0.5460288658143235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's self_metric: 0.932305\tvalid_1's self_metric: 0.898573\n",
      "[140]\tvalid_0's self_metric: 0.962752\tvalid_1's self_metric: 0.922055\n",
      "[210]\tvalid_0's self_metric: 0.97306\tvalid_1's self_metric: 0.932821\n",
      "[280]\tvalid_0's self_metric: 0.976313\tvalid_1's self_metric: 0.935701\n",
      "[350]\tvalid_0's self_metric: 0.977728\tvalid_1's self_metric: 0.935447\n",
      "[420]\tvalid_0's self_metric: 0.978585\tvalid_1's self_metric: 0.935612\n",
      "[490]\tvalid_0's self_metric: 0.979315\tvalid_1's self_metric: 0.935993\n",
      "[560]\tvalid_0's self_metric: 0.979494\tvalid_1's self_metric: 0.935959\n",
      "[630]\tvalid_0's self_metric: 0.979711\tvalid_1's self_metric: 0.936015\n",
      "[700]\tvalid_0's self_metric: 0.97973\tvalid_1's self_metric: 0.935572\n",
      "inner_predict 472431\n",
      "ROC AUC 0.9797191571278775\n",
      "inner_predict 354324\n",
      "debug: 0.935482181625161 0.7538628937762186 (0.8464278881701749, 0.402804126958349, 0.5458467961093827)\n",
      "debug: 0.9437096146341638 0.0952402125192711 (0.7332142195307009, 0.515992824820805, 0.6057174878177706)\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in X_train.columns ]  \n",
    "cate = []\n",
    "print(cate)\n",
    "num_label = 3  \n",
    "params = {'objective': 'custom',\n",
    "          'num_labels':num_label, \n",
    "          'tree_learner': 'serial2',\n",
    "          'boosting': 'gbdt',\n",
    "          'max_depth': 16,\n",
    "          'learning_rate': 0.03,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'feature_fraction': 0.9,\n",
    "          'verbosity': -1,\n",
    "          'lambda_l1': 0.5,\n",
    "          'lambda_l2': 0.05,\n",
    "          'num_leaves': 500,\n",
    "          'min_child_weight': 0.1,\n",
    "          'min_data_in_leaf': 25,\n",
    "          \"num_threads\":18,\n",
    "          'metric_freq':10,\n",
    "          'data_random_seed': 17}\n",
    "print(params)\n",
    "early_stop = 500\n",
    "verbose_eval = 70\n",
    "num_rounds = 750\n",
    "# \n",
    "\n",
    "for target_col in [[0,2],[2,3],[0,3]]:\n",
    "    print(target_col)\n",
    "    folds = 3\n",
    "    kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "    y_preds22 = np.zeros(X_test.shape[0])\n",
    "    y_oof = np.zeros(X_train.shape[0])\n",
    "    i = 0\n",
    "    for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "\n",
    "        def self_metric(preds, train_data):\n",
    "            labels = train_data.get_label()\n",
    "            labels2 = labels.reshape((num_label,-1)).transpose()[:,0]\n",
    "            preds2 = preds.reshape((num_label,-1)).transpose()[:,0]\n",
    "            preds2 = 1. / (1. + np.exp(-preds2))\n",
    "            score = roc_auc_score(labels2, preds2)\n",
    "            return 'self_metric', score, False\n",
    "  \n",
    "\n",
    "        def mymse3(preds, train_data, ep = 0):\n",
    "            labels = train_data.get_label()\n",
    "            labels2 = labels.reshape((num_label,-1)).transpose()\n",
    "            preds2 = preds.reshape((num_label,-1)).transpose()\n",
    "\n",
    "            labels2 = np.clip(labels2,0,1)\n",
    "\n",
    "            preds3 = 1. / (1. + np.exp(-preds2))\n",
    "            grad2 = preds3 - labels2\n",
    "            hess2 = preds3 * (1. - preds3)\n",
    "\n",
    "            import random\n",
    "            beta = 0.5\n",
    "            w = np.array([1,0.1 * beta,0.1 * beta])\n",
    "            w2 = np.array([1.0,1.0,1.0])\n",
    "\n",
    "            grad = (grad2) * np.array(w)\n",
    "            grad = np.sum(grad,axis = 1)\n",
    "            grad2 = (grad2 * w2).transpose().reshape((-1))\n",
    "\n",
    "            hess = np.sum((hess2) * np.array(w),axis = 1)\n",
    "            return grad, hess, grad2, hess2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        X_tr, X_vl = X_train[features].iloc[tr_idx, :], X_train[features].iloc[val_idx, :]\n",
    "        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        target = target_col\n",
    "        y_tr2, y_vl2 = y_train_s.iloc[tr_idx, target], y_train_s.iloc[val_idx, target]\n",
    "        d_train = lgb.Dataset(X_tr, label=np.concatenate([y_tr.values.reshape((-1,1)),y_tr2.values],axis = 1),categorical_feature = cate)\n",
    "        d_valid = lgb.Dataset(X_vl, label=np.concatenate([y_vl.values.reshape((-1,1)),y_vl2.values],axis = 1),categorical_feature = cate)\n",
    "        watchlist = [d_valid]\n",
    "        if debug:\n",
    "            d_test = lgb.Dataset(X_test[features], label=np.concatenate([y_test.values.reshape((-1,1)),y_test_s.values[:,target]],axis = 1),categorical_feature = cate)\n",
    "            watchlist.append(d_test)\n",
    "\n",
    "\n",
    "        model = lgb.train(params,\n",
    "                          train_set=d_train,\n",
    "                          num_boost_round=num_rounds,\n",
    "                          valid_sets=watchlist,\n",
    "                          verbose_eval=verbose_eval,\n",
    "                         fobj = mymse3,\n",
    "                         feval = self_metric\n",
    "                         )\n",
    "        model.set_num_labels(num_label)\n",
    "\n",
    "        y_pred_train = model.predict(X_vl)[:,0]\n",
    "        y_oof[val_idx] = y_pred_train\n",
    "        print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "\n",
    "        temp = model.predict(X_test[features])[:,0]\n",
    "        y_preds22 += (1. / (1. + np.exp(-temp))) / folds\n",
    "\n",
    "        if debug:    \n",
    "            print(\"debug:\",roc_auc_score(y_test, temp),log_loss(y_test, temp),metric(y_test, temp))  \n",
    "        i+=1\n",
    "\n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, y_preds22),log_loss(y_test, y_preds22),metric(y_test, y_preds22))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{'objective': 'custom', 'num_labels': 4, 'tree_learner': 'serial2', 'boosting': 'gbdt', 'max_depth': 16, 'learning_rate': 0.03, 'bagging_fraction': 0.9, 'feature_fraction': 0.9, 'verbosity': -1, 'lambda_l1': 0.5, 'lambda_l2': 0.05, 'num_leaves': 500, 'min_child_weight': 0.1, 'min_data_in_leaf': 25, 'num_threads': 8, 'metric_freq': 10, 'data_random_seed': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's self_metric: 0.913959\tvalid_1's self_metric: 0.884112\n",
      "[60]\tvalid_0's self_metric: 0.925524\tvalid_1's self_metric: 0.897179\n",
      "[90]\tvalid_0's self_metric: 0.941345\tvalid_1's self_metric: 0.909084\n",
      "[120]\tvalid_0's self_metric: 0.954033\tvalid_1's self_metric: 0.918314\n",
      "[150]\tvalid_0's self_metric: 0.962815\tvalid_1's self_metric: 0.926431\n",
      "[180]\tvalid_0's self_metric: 0.968379\tvalid_1's self_metric: 0.931035\n",
      "[210]\tvalid_0's self_metric: 0.971857\tvalid_1's self_metric: 0.93528\n",
      "[240]\tvalid_0's self_metric: 0.973736\tvalid_1's self_metric: 0.937771\n",
      "[270]\tvalid_0's self_metric: 0.974792\tvalid_1's self_metric: 0.9391\n",
      "[300]\tvalid_0's self_metric: 0.975715\tvalid_1's self_metric: 0.939458\n",
      "[330]\tvalid_0's self_metric: 0.976178\tvalid_1's self_metric: 0.939846\n",
      "[360]\tvalid_0's self_metric: 0.976807\tvalid_1's self_metric: 0.939815\n",
      "[390]\tvalid_0's self_metric: 0.977234\tvalid_1's self_metric: 0.939819\n",
      "[420]\tvalid_0's self_metric: 0.977228\tvalid_1's self_metric: 0.940054\n",
      "[450]\tvalid_0's self_metric: 0.977331\tvalid_1's self_metric: 0.9402\n",
      "[480]\tvalid_0's self_metric: 0.977394\tvalid_1's self_metric: 0.940182\n",
      "inner_predict 629912\n",
      "ROC AUC 0.9774096852002522\n",
      "inner_predict 472432\n",
      "debug: 0.9402808673858991 0.7498891644837196 (0.8423449647348545, 0.402312002185034, 0.5445443978537956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's self_metric: 0.912511\tvalid_1's self_metric: 0.883542\n",
      "[60]\tvalid_0's self_metric: 0.925968\tvalid_1's self_metric: 0.897423\n",
      "[90]\tvalid_0's self_metric: 0.940532\tvalid_1's self_metric: 0.905445\n",
      "[120]\tvalid_0's self_metric: 0.954049\tvalid_1's self_metric: 0.916277\n",
      "[150]\tvalid_0's self_metric: 0.964517\tvalid_1's self_metric: 0.925548\n",
      "[180]\tvalid_0's self_metric: 0.969726\tvalid_1's self_metric: 0.931618\n",
      "[210]\tvalid_0's self_metric: 0.97239\tvalid_1's self_metric: 0.934897\n",
      "[240]\tvalid_0's self_metric: 0.974211\tvalid_1's self_metric: 0.937499\n",
      "[270]\tvalid_0's self_metric: 0.975233\tvalid_1's self_metric: 0.938714\n",
      "[300]\tvalid_0's self_metric: 0.975981\tvalid_1's self_metric: 0.939609\n",
      "[330]\tvalid_0's self_metric: 0.976441\tvalid_1's self_metric: 0.94007\n",
      "[360]\tvalid_0's self_metric: 0.976731\tvalid_1's self_metric: 0.939958\n",
      "[390]\tvalid_0's self_metric: 0.977026\tvalid_1's self_metric: 0.940049\n",
      "[420]\tvalid_0's self_metric: 0.977119\tvalid_1's self_metric: 0.940354\n",
      "[450]\tvalid_0's self_metric: 0.977346\tvalid_1's self_metric: 0.940501\n",
      "[480]\tvalid_0's self_metric: 0.977395\tvalid_1's self_metric: 0.940687\n",
      "inner_predict 629908\n",
      "ROC AUC 0.977468033697642\n",
      "inner_predict 472432\n",
      "debug: 0.940886831270677 0.7635818911234373 (0.8409519701041055, 0.39812894161185625, 0.5404123566721554)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbmmt/basic.py:1297: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's self_metric: 0.920312\tvalid_1's self_metric: 0.884612\n",
      "[60]\tvalid_0's self_metric: 0.931183\tvalid_1's self_metric: 0.895516\n",
      "[90]\tvalid_0's self_metric: 0.943853\tvalid_1's self_metric: 0.908349\n",
      "[120]\tvalid_0's self_metric: 0.955888\tvalid_1's self_metric: 0.918047\n",
      "[150]\tvalid_0's self_metric: 0.964566\tvalid_1's self_metric: 0.924205\n",
      "[180]\tvalid_0's self_metric: 0.970086\tvalid_1's self_metric: 0.930442\n",
      "[210]\tvalid_0's self_metric: 0.972659\tvalid_1's self_metric: 0.93343\n",
      "[240]\tvalid_0's self_metric: 0.974581\tvalid_1's self_metric: 0.935108\n",
      "[270]\tvalid_0's self_metric: 0.975925\tvalid_1's self_metric: 0.936286\n",
      "[300]\tvalid_0's self_metric: 0.976705\tvalid_1's self_metric: 0.936692\n",
      "[330]\tvalid_0's self_metric: 0.97724\tvalid_1's self_metric: 0.936997\n",
      "[360]\tvalid_0's self_metric: 0.977638\tvalid_1's self_metric: 0.937132\n",
      "[390]\tvalid_0's self_metric: 0.977918\tvalid_1's self_metric: 0.937458\n",
      "[420]\tvalid_0's self_metric: 0.978295\tvalid_1's self_metric: 0.938024\n",
      "[450]\tvalid_0's self_metric: 0.978506\tvalid_1's self_metric: 0.938224\n",
      "[480]\tvalid_0's self_metric: 0.978605\tvalid_1's self_metric: 0.938356\n",
      "inner_predict 629908\n",
      "ROC AUC 0.9787122023669346\n",
      "inner_predict 472432\n",
      "debug: 0.9383649207813699 0.7550063474511024 (0.8350472420245256, 0.39862106638517125, 0.5396384422436967)\n",
      "debug: 0.945400919043679 0.08579426596112219 (0.7119898034410109, 0.534693566206776, 0.6107346522353786)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = [x for x in X_train.columns ]  \n",
    "cate = []\n",
    "print(cate)\n",
    "num_label = 4  \n",
    "params = { 'objective': 'custom',\n",
    "          'num_labels':num_label, \n",
    "          'tree_learner': 'serial2',\n",
    "          'boosting': 'gbdt',\n",
    "          'max_depth': 16,\n",
    "          'learning_rate': 0.03,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'feature_fraction': 0.9,\n",
    "          'verbosity': -1,\n",
    "          'lambda_l1': 0.5,\n",
    "          'lambda_l2': 0.05,\n",
    "          'num_leaves': 500,\n",
    "          'min_child_weight': 0.1,\n",
    "          'min_data_in_leaf': 25,\n",
    "          \"num_threads\":8,\n",
    "          'metric_freq':10,\n",
    "          'data_random_seed': 17}\n",
    "print(params)\n",
    "early_stop = 500\n",
    "verbose_eval = 30\n",
    "num_rounds = 500\n",
    "# \n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_lgbmt = np.zeros(X_test.shape[0])\n",
    "y_lgbmtsub = np.zeros((X_test.shape[0],4))\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "i = 0\n",
    "sub_task = [0,2,3]\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "      \n",
    "    def self_metric(preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        labels2 = labels.reshape((num_label,-1)).transpose()[:,0]\n",
    "        preds2 = preds.reshape((num_label,-1)).transpose()[:,0]\n",
    "        preds2 = 1. / (1. + np.exp(-preds2))\n",
    "        score = roc_auc_score(labels2, preds2)\n",
    "        return 'self_metric', score, False\n",
    "\n",
    "    \n",
    "    def mymse2(preds, train_data, ep = 0):\n",
    "        labels = train_data.get_label()\n",
    "        labels2 = labels.reshape((num_label,-1)).transpose()\n",
    "        preds2 = preds.reshape((num_label,-1)).transpose()\n",
    "        labels2 = np.clip(labels2,0,1)\n",
    "        \n",
    "        preds3 = 1. / (1. + np.exp(-preds2))\n",
    "        grad2 = preds3 - labels2\n",
    "        hess2 = grad2 * 0. + 1\n",
    "        hess2 = preds3 * (1. - preds3)\n",
    "        \n",
    "        import random\n",
    "        beta = max(0.0,0.5 - 0.2 * (ep//100)) * 2\n",
    "        beta = 0.2\n",
    "        w = np.array([1,0.1 * beta,0.1 * beta,0.1 * beta])\n",
    "        w2 = np.array([1.0,1.0,1.0,1.0])\n",
    "\n",
    "        grad = (grad2) * np.array(w)\n",
    "        grad = np.sum(grad,axis = 1)\n",
    "        grad2 = (grad2 * w2).transpose().reshape((-1))\n",
    "            \n",
    "        hess = np.sum(hess2 * np.array(w),axis = 1)\n",
    "        return grad, hess, grad2, hess2  \n",
    "\n",
    "    X_tr, X_vl = X_train[features].iloc[tr_idx, :], X_train[features].iloc[val_idx, :]\n",
    "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    y_tr2, y_vl2 = y_train_s.iloc[tr_idx, sub_task], y_train_s.iloc[val_idx, sub_task]\n",
    "    d_train = lgb.Dataset(X_tr, label=np.concatenate([y_tr.values.reshape((-1,1)),y_tr2.values],axis = 1),categorical_feature = cate)\n",
    "    d_valid = lgb.Dataset(X_vl, label=np.concatenate([y_vl.values.reshape((-1,1)),y_vl2.values],axis = 1),categorical_feature = cate)\n",
    "    watchlist = [d_valid]\n",
    "    if debug:\n",
    "        d_test = lgb.Dataset(X_test[features], label=np.concatenate([y_test.values.reshape((-1,1)),y_test_s.values[:,[0,2,3]]],axis = 1),categorical_feature = cate)\n",
    "        watchlist.append(d_test)\n",
    "    \n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval,\n",
    "                     fobj = mymse2,\n",
    "                     feval = self_metric\n",
    "                     )\n",
    "    model.set_num_labels(num_label)\n",
    "        \n",
    "    y_pred_train = model.predict(X_vl)[:,0]\n",
    "    y_oof[val_idx] = y_pred_train\n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "    \n",
    "    temp = model.predict(X_test[features])\n",
    "    y_lgbmt += (1. / (1. + np.exp(-temp[:,0]))) / folds\n",
    "    y_lgbmtsub += (1. / (1. + np.exp(-temp))) / folds\n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, temp[:,0]),log_loss(y_test, temp[:,0]),metric(y_test, temp[:,0]))  \n",
    "    i+=1\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_lgbmt),log_loss(y_test, y_lgbmt),metric(y_test, y_lgbmt))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in X_train.columns ]  \n",
    "cate = []\n",
    "print(cate)\n",
    "num_label = 5  \n",
    "params = { 'objective': 'custom',\n",
    "          'num_labels':num_label, \n",
    "          'tree_learner': 'serial2',\n",
    "          'boosting': 'gbdt',\n",
    "          'max_depth': 16,\n",
    "          'learning_rate': 0.03,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'feature_fraction': 0.9,\n",
    "          'verbosity': -1,\n",
    "          'lambda_l1': 0.5,\n",
    "          'lambda_l2': 0.05,\n",
    "          'num_leaves': 500,\n",
    "          'min_child_weight': 0.1,\n",
    "          'min_data_in_leaf': 25,\n",
    "          \"num_threads\":18,\n",
    "          'metric_freq':10,\n",
    "          'data_random_seed': 17}\n",
    "print(params)\n",
    "early_stop = 500\n",
    "verbose_eval = 30\n",
    "num_rounds = 750\n",
    "# \n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_preds22 = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "      \n",
    "    def self_metric(preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        labels2 = labels.reshape((num_label,-1)).transpose()[:,0]\n",
    "        preds2 = preds.reshape((num_label,-1)).transpose()[:,0]\n",
    "        preds2 = 1. / (1. + np.exp(-preds2))\n",
    "        score = roc_auc_score(labels2, preds2)\n",
    "        return 'self_metric', score, False\n",
    "\n",
    "    def self_metric2(preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        labels2 = labels.reshape((num_label,-1)).transpose()[:,0]\n",
    "        preds2 = preds.reshape((num_label,-1)).transpose()[:,0]\n",
    "        preds2 = 1. / (1. + np.exp(-preds2))\n",
    "        score = log_loss(labels2, preds2)\n",
    "        return 'self_metric', score, False    \n",
    "    \n",
    "    def mymse3(preds, train_data, ep = 0):\n",
    "        labels = train_data.get_label()\n",
    "        labels2 = labels.reshape((num_label,-1)).transpose()\n",
    "        preds2 = preds.reshape((num_label,-1)).transpose()\n",
    "        \n",
    "        labels2 = np.clip(labels2,0,1)\n",
    "        \n",
    "        preds3 = 1. / (1. + np.exp(-preds2))\n",
    "        grad2 = preds3 - labels2\n",
    "        hess2 = preds3 * (1. - preds3)\n",
    "        \n",
    "        grad2[:,-1] = (preds2 - labels2)[:,-1]\n",
    "        hess2[:,-1] = hess2[:,-1] * 0. + 0\n",
    "        import random\n",
    "        beta2 = max(0.0,0.4 - 0.2 * (ep//50)) * 0.5\n",
    "        beta = 0.2\n",
    "        w = np.array([1,0.1 * beta,0.1 * beta,0.1 * beta,beta2])\n",
    "        w2 = np.array([1.0,1.0,1.0,1.0,1.0])\n",
    "\n",
    "        grad = (grad2) * np.array(w)\n",
    "        grad = np.sum(grad,axis = 1)\n",
    "        grad2 = (grad2 * w2).transpose().reshape((-1))\n",
    "            \n",
    "        hess = np.sum((hess2) * np.array(w),axis = 1)\n",
    "        hess2[:,-1] = hess2[:,-1] * 0. + 1\n",
    "        return grad, hess, grad2, hess2 \n",
    "     \n",
    "\n",
    "    X_tr, X_vl = X_train[features].iloc[tr_idx, :], X_train[features].iloc[val_idx, :]\n",
    "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    target = [0,2,3,6]\n",
    "    y_tr2, y_vl2 = y_train_s.iloc[tr_idx, target], y_train_s.iloc[val_idx, target]\n",
    "    d_train = lgb.Dataset(X_tr, label=np.concatenate([y_tr.values.reshape((-1,1)),y_tr2.values],axis = 1),categorical_feature = cate)\n",
    "    d_valid = lgb.Dataset(X_vl, label=np.concatenate([y_vl.values.reshape((-1,1)),y_vl2.values],axis = 1),categorical_feature = cate)\n",
    "    watchlist = [d_valid]\n",
    "    if debug:\n",
    "        d_test = lgb.Dataset(X_test[features], label=np.concatenate([y_test.values.reshape((-1,1)),y_test_s.values[:,target]],axis = 1),categorical_feature = cate)\n",
    "        watchlist.append(d_test)\n",
    "    \n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval,\n",
    "                     fobj = mymse3,\n",
    "                     feval = self_metric\n",
    "                     )\n",
    "    model.set_num_labels(num_label)\n",
    "        \n",
    "    y_pred_train = model.predict(X_vl)[:,0]\n",
    "    y_oof[val_idx] = y_pred_train\n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "    \n",
    "    temp = model.predict(X_test[features])[:,0]\n",
    "    print(temp[:10])\n",
    "    y_preds22 += (1. / (1. + np.exp(-temp))) / folds\n",
    "    \n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, temp),log_loss(y_test, temp),metric(y_test, temp))  \n",
    "    i+=1\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds22),log_loss(y_test, y_preds22),metric(y_test, y_preds22))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Multi-Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "\n",
    "class ContinuousFeatureConverter:\n",
    "    def __init__(self, name, feature, log_transform):\n",
    "        self.name = name\n",
    "        self.skew = feature.skew()\n",
    "        self.log_transform = log_transform\n",
    "        \n",
    "    def transform(self, feature):\n",
    "        if self.skew > 1:\n",
    "            feature = self.log_transform(feature)\n",
    "        \n",
    "        mean = feature.astype(np.float32).mean()\n",
    "        std = feature.astype(np.float32).std()\n",
    "#         print((feature - mean)/(std + 1e-6) )\n",
    "        return (feature - mean)/(std + 1e-6)   \n",
    "    \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "def categorical_encode(df_train, df_valid, df_test, categorical_features, n_values=50):\n",
    "    df_train = df_train[categorical_features].astype(str)\n",
    "    df_valid = df_valid[categorical_features].astype(str)\n",
    "    df_test = df_test[categorical_features].astype(str)\n",
    "    \n",
    "    categories = []\n",
    "    for column in tqdm(categorical_features):\n",
    "        categories.append(list(df_train[column].value_counts().iloc[: n_values - 1].index) + ['Other'])\n",
    "        values2use = categories[-1]\n",
    "        df_train[column] = df_train[column].apply(lambda x: x if x in values2use else 'Other')\n",
    "        df_valid[column] = df_valid[column].apply(lambda x: x if x in values2use else 'Other')\n",
    "        df_test[column] = df_test[column].apply(lambda x: x if x in values2use else 'Other')\n",
    "        \n",
    "    \n",
    "    ohe = OneHotEncoder(categories=categories)\n",
    "    ohe.fit(pd.concat([df_train, df_test]))\n",
    "    df_train = pd.DataFrame(ohe.transform(df_train).toarray()).astype(np.float16)\n",
    "    df_valid = pd.DataFrame(ohe.transform(df_valid).toarray()).astype(np.float16)\n",
    "    df_test = pd.DataFrame(ohe.transform(df_test).toarray()).astype(np.float16)\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "import keras\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.utils.generic_utils import get_custom_objects\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         print(pt_0.shape)\n",
    "        weight = tf.Variable([1.0,0.1,0.1,0.1], name='xxx')\n",
    "        return -K.mean((alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1)\n",
    "                      )*weight)-K.mean(((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))*weight)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "num_label = 4\n",
    "\n",
    "def create_model(loss_fn,X_tr):\n",
    "    inps = Input(shape=(X_tr.shape[1],))\n",
    "    x = Dense(512, activation=custom_gelu)(inps)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation=custom_gelu)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(4, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inps, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=[focal_loss()]\n",
    "    )\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val[:,0], y_pred_val[:,0])\n",
    "        print('\\rroc-auc_val: %s' % (str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "features = [x for x in X_train.columns if not x.endswith(\"count\")]  \n",
    "categorical_features = [\n",
    "    'ProductCD',\n",
    "    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "    'addr1', 'addr2',\n",
    "    'P_emaildomain',\n",
    "    'R_emaildomain',\n",
    "    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9','id_31_raw',\n",
    "    'id_30_raw',\n",
    "    'DeviceInfo_raw',\n",
    "    'card123456_add1_D11_series',\n",
    "    'card123456_add1_D8_series',\n",
    "    'id_12',\n",
    "    'id_15',\n",
    "    'id_16',\n",
    "    'id_23',\n",
    "    'id_27',\n",
    "    'id_28',\n",
    "    'id_29',\n",
    "    'id_30',\n",
    "    'id_31',\n",
    "    'id_33',\n",
    "    'id_34',\n",
    "    'id_35',\n",
    "    'id_36',\n",
    "    'id_37',\n",
    "    'id_38',\n",
    "    'DeviceType',\n",
    "    'DeviceInfo'\n",
    "]\n",
    "categorical_features = [x for x in features if (x == 'ProductCD' or x in ['card1','card2'] or  x.startswith(\"addr\") or \n",
    "                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") and not x == \"id_11\" \n",
    "       ]\n",
    "features_continue = [x for x in X_train.columns if x not in categorical_features]\n",
    "cate = []\n",
    "num_label = 4  \n",
    "early_stop = 500\n",
    "verbose_eval = 30\n",
    "num_rounds = 500\n",
    "# \n",
    "folds = 3\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed)\n",
    "y_preds22 = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "      \n",
    "\n",
    "    X_tr, X_vl = X_train[features].iloc[tr_idx, :].fillna(0), X_train[features].iloc[val_idx, :].fillna(0)\n",
    "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    y_tr2, y_vl2 = y_train_s.iloc[tr_idx, [0,2,3]], y_train_s.iloc[val_idx, [0,2,3]]\n",
    "    y_tr = np.concatenate([y_tr.values.reshape((-1,1)),y_tr2.values],axis = 1)\n",
    "    y_vl = np.concatenate([y_vl.values.reshape((-1,1)),y_vl2.values],axis = 1)\n",
    "    y_test2 = np.concatenate([y_test.values.reshape((-1,1)),y_test_s.values[:,[0,2,3]]],axis = 1)\n",
    "    X_test2 = X_test[features].fillna(0).copy()\n",
    "    for f in features_continue:\n",
    "        log = lambda x: np.log10(x + 1 - min(0, x.min()))\n",
    "        converter = ContinuousFeatureConverter(f, X_tr[f], log)\n",
    "        X_tr[f] = converter.transform(X_tr[f])\n",
    "        X_vl[f] = converter.transform(X_vl[f])\n",
    "        X_test2[f] = converter.transform(X_test[f])\n",
    " \n",
    "    train_categorical, valid_categorical, test_categorical = categorical_encode(X_tr, X_vl, X_test2, categorical_features)\n",
    "    X_tr = np.concatenate([X_tr.fillna(0).values, train_categorical.values], axis=1)\n",
    "    del train_categorical\n",
    "    X_vl = np.concatenate([X_vl.fillna(0).values, valid_categorical.values], axis=1)\n",
    "    del valid_categorical\n",
    "    X_test2 = np.concatenate([X_test2.fillna(0).values, test_categorical.values], axis=1)\n",
    "    del test_categorical\n",
    "    model = create_model('binary_crossentropy',X_tr)\n",
    "    model.fit(\n",
    "        X_tr, y_tr, epochs=8, batch_size=2048, validation_data=(X_test2, y_test2), verbose=True, \n",
    "    callbacks=[roc_callback(training_data=(X_tr, y_tr), validation_data=(X_test2, y_test2))])\n",
    "        \n",
    "    y_pred_train = model.predict(X_vl)[:,0]\n",
    "    y_oof[val_idx] = y_pred_train\n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl[:,0], y_pred_train)))\n",
    "    \n",
    "    temp = model.predict(X_test2)[:,0]\n",
    "    y_preds22 += (1. / (1. + np.exp(-temp))) / folds\n",
    "    \n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, temp),log_loss(y_test, temp),metric(y_test, temp))  \n",
    "    i+=1\n",
    "    del X_test2\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds22),log_loss(y_test, y_preds22),metric(y_test, y_preds22))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118108, 4), (118108,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_lgbmtsub.shape,y_singlelgb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roc-auc for sub-tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "res = [0] * 4\n",
    "res2 = [0] * 4\n",
    "res3 = [0] * 4\n",
    "y_test2 = np.concatenate([y_test.values.reshape((-1,1)),y_test_s.values[:,[0,2,3]]],axis = 1).clip(0,1)\n",
    "for i in range(y_lgbmtsub.shape[0]):\n",
    "    for j in range(4):\n",
    "        if y_test2[i,j] == 1:\n",
    "            res[j] += 1\n",
    "#             if y_singlelgb[i] > 0.3:\n",
    "            res2[j] += y_singlelgb[i]\n",
    "#             if y_lgbmtsub[i,0] > 0.3:\n",
    "            res3[j] += y_lgbmtsub[i,0]\n",
    "    \n",
    "bar1 = plt.bar(x = [i - 0.3 for i in range(len(res))], height = res, width = 0.2,\n",
    "               alpha = 0.8, color = 'r',label = 'gt')  \n",
    "\n",
    "bar2 = plt.bar(x = [i - 0.1 for i in range(len(res))], height = res2, width = 0.2,\n",
    "               alpha = 0.8, color = 'y',label = 'baseline')                  \n",
    "\n",
    "bar3 = plt.bar(x = [i + 0.1 for i in range(len(res))], height = res3,width = 0.2,\n",
    "               alpha = 0.8,color = 'g',label = 'mt-gbm')                   \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1] [0.9442728771696625, 0.8404125767539823, 0.9684661390767818, 0.9375276669444391] [0.945400919043679, 0.8589601155349836, 0.9702270283501425, 0.9410505358537014]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = [0] * 4\n",
    "res2 = [0] * 4\n",
    "res3 = [0] * 4    \n",
    "for j in range(4):\n",
    "    res[j] = 1\n",
    "    res2[j] = roc_auc_score(y_test2[:,j], y_singlelgb[:])\n",
    "    res3[j] = roc_auc_score(y_test2[:,j], y_lgbmtsub[:,0])\n",
    "\n",
    "bar1 = plt.bar(x = [i - 0.2 for i in range(len(res))], height = res, width = 0.2,\n",
    "               alpha = 0.8, color = 'r',label = 'gt label')  \n",
    "\n",
    "bar2 = plt.bar(x = [i - 0 for i in range(len(res))], height = res2, width = 0.2,\n",
    "               alpha = 0.8, color = 'y',label = 'baseline(lgb)')                  \n",
    "\n",
    "bar3 = plt.bar(x = [i + 0.2 for i in range(len(res))], height = res3,width = 0.2,\n",
    "               alpha = 0.8,color = 'g',label = 'mt-gbm(main task)')                   \n",
    "print(res,res2,res3)\n",
    "plt.ylim(0.8,1.1)\n",
    "plt.xlabel('Task index') \n",
    "plt.ylabel('Roc-auc') \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1] [0.9442728771696625, 0.8404125767539823, 0.9684661390767818, 0.9375276669444391] [0.945400919043679, 0.9491546036849549, 0.9924255714013507, 0.9639497661490082]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = [0] * 4\n",
    "res2 = [0] * 4\n",
    "res3 = [0] * 4 \n",
    "res4 = [0] * 4     \n",
    "for j in range(4):\n",
    "    res[j] = 1\n",
    "    res2[j] = roc_auc_score(y_test2[:,j], y_singlelgb[:])\n",
    "    res3[j] = roc_auc_score(y_test2[:,j], y_lgbmtsub[:,j])\n",
    "    res4[j] = roc_auc_score(y_test2[:,j], y_lgbmtsub[:,0])\n",
    "\n",
    "\n",
    "bar2 = plt.bar(x = [i - 0.2 for i in range(len(res))], height = res2, width = 0.2,\n",
    "               alpha = 0.8, color = 'y',label = 'baseline(lgb)')                  \n",
    "bar1 = plt.bar(x = [i - 0.0 for i in range(len(res))], height = res4, width = 0.2,\n",
    "               alpha = 0.8, color = 'r',label = 'mt-gbm(main task)') \n",
    "bar3 = plt.bar(x = [i + 0.2 for i in range(len(res))], height = res3,width = 0.2,\n",
    "               alpha = 0.8,color = 'g',label = 'mt-gbm(sub tasks)')                   \n",
    "print(res,res2,res3)\n",
    "plt.ylim(0.8,1.1)\n",
    "plt.xlabel('Task index') \n",
    "plt.ylabel('Roc-auc') \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
